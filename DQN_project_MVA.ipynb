{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You may need to install [OpenCV](https://pypi.python.org/pypi/opencv-python) and [scikit-video](http://www.scikit-video.org/stable/).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import io\n",
    "import base64\n",
    "from IPython.display import HTML\n",
    "import skvideo.io\n",
    "import cv2\n",
    "import json\n",
    "import ipdb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.models import Sequential,model_from_json\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Activation, AveragePooling2D,Reshape,BatchNormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MiniProject on Deep Reinforcement Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Notations__: $E_p$ is the expectation under probability $p$. Please justify each of your answer and widely comment your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a reinforcement learning algorithm, we modelize each step $t$ as an action $a_t$ obtained from a state $s_t$, i.e. $\\{(a_{t},s_{t})_{t\\leq T}\\}$ having the Markov property. We consider a discount factor $\\gamma \\in [0,1]$ that ensures convergence. The goal is to find among all the policies $\\pi$, one that maximizes the expected reward:\n",
    "\n",
    "\\begin{equation*}\n",
    "R(\\pi)=\\sum_{t\\leq T}E_{p^{\\pi}}[\\gamma^t r(s_{t},a_{t})] \\> ,\n",
    "\\end{equation*}\n",
    "\n",
    "where: \n",
    "\\begin{equation*}p^{\\pi}(a_{0},a_{1},s_{1},...,a_{T},s_{T})=p(a_{0})\\prod_{t=1}^{T}\\pi(a_{t}|s_{t})p(s_{t+1}|s_{t},a_{t}) \\> .\n",
    "\\end{equation*}\n",
    "\n",
    "We note the $Q$-function:\n",
    "\n",
    "\\begin{equation*}Q^\\pi(s,a)=E_{p^{\\pi}}[\\sum_{t\\leq T}\\gamma^{t}r(s_{t},a_{t})|s_{0}=s,a_{0}=a] \\> .\n",
    "\\end{equation*}\n",
    "\n",
    "Thus, the optimal Q function is:\n",
    "\\begin{equation*}\n",
    "Q^*(s,a)=\\max_{\\pi}Q^\\pi(s,a) \\> .\n",
    "\\end{equation*}\n",
    "\n",
    "In this project, we will apply the deep reinforcement learning techniques to a simple game: an agent will have to learn from scratch a policy that will permit it maximizing a reward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The environment, the agent and the game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Environment``` is an abstract class that represents the states, rewards, and actions to obtain the new state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def act(self, act):\n",
    "        \"\"\"\n",
    "        One can act on the environment and obtain its reaction:\n",
    "        - the new state\n",
    "        - the reward of the new state\n",
    "        - should we continue the game?\n",
    "\n",
    "        :return: state, reward, game_over\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        Reinitialize the environment to a random state and returns\n",
    "        the original state\n",
    "\n",
    "        :return: state\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def draw(self):\n",
    "        \"\"\"\n",
    "        Visualize in the console or graphically the current state\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method ```act``` allows to act on the environment at a given state $s_t$ (stored internally), via action $a_t$. The method will return the new state $s_{t+1}$, the reward $r(s_{t},a_{t})$ and determines if $t\\leq T$ (*game_over*).\n",
    "\n",
    "The method ```reset``` simply reinitializes the environment to a random state $s_0$.\n",
    "\n",
    "The method ```draw``` displays the current state $s_t$ (this is useful to check the behavior of the Agent).\n",
    "\n",
    "We modelize $s_t$ as a tensor, while $a_t$ is an integer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of the ```Agent``` is to interact with the ```Environment``` by proposing actions $a_t$ obtained from a given state $s_t$ to attempt to maximize its __reward__ $r(s_t,a_t)$. We propose the following abstract class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent(object):\n",
    "    def __init__(self, epsilon=0.1, n_action=4):\n",
    "        self.epsilon = epsilon\n",
    "        self.n_action = n_action\n",
    "    \n",
    "    def set_epsilon(self,e):\n",
    "        self.epsilon = e\n",
    "\n",
    "    def act(self,s,train=True):\n",
    "        \"\"\" This function should return the next action to do:\n",
    "        an integer between 0 and 4 (not included) with a random exploration of epsilon\"\"\"\n",
    "        if train:\n",
    "            if np.random.rand() <= self.epsilon:\n",
    "                a = np.random.randint(0, self.n_action, size=1)[0]\n",
    "            else:\n",
    "                a = self.learned_act(s)\n",
    "        else: # in some cases, this can improve the performance.. remove it if poor performances\n",
    "            a = self.learned_act(s)\n",
    "\n",
    "        return a\n",
    "\n",
    "    def learned_act(self,s):\n",
    "        \"\"\" Act via the policy of the agent, from a given state s\n",
    "        it proposes an action a\"\"\"\n",
    "        pass\n",
    "\n",
    "    def reinforce(self, s, n_s, a, r, game_over_):\n",
    "        \"\"\" This function is the core of the learning algorithm. \n",
    "        It takes as an input the current state s_, the next state n_s_\n",
    "        the action a_ used to move from s_ to n_s_ and the reward r_.\n",
    "        \n",
    "        Its goal is to learn a policy.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def save(self):\n",
    "        \"\"\" This function returns basic stats if applicable: the\n",
    "        loss and/or the model\"\"\"\n",
    "        pass\n",
    "\n",
    "    def load(self):\n",
    "        \"\"\" This function allows to restore a model\"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "__Question 1__:\n",
    "Explain the function act. Why is ```epsilon``` essential?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the start of the game, the agent has not yet explored all the possibilities, therefore all the rewards possible.\n",
    "If he always goes for the action learnt by his current policy (giving him the maximum short term reward for ex), then he will always do the same thing, and maybe miss an action giving him less reward immediately, but will give him later a way better total reward.\n",
    "epsilon is there to ensure we have at least some exploration to avoid the situation described above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### The Game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ```Agent``` and the ```Environment``` work in an interlaced way as in the following (take some time to understand this code as it is the core of the project)\n",
    "\n",
    "```python\n",
    "\n",
    "epoch = 300\n",
    "env = Environment()\n",
    "agent = Agent()\n",
    "\n",
    "\n",
    "# Number of won games\n",
    "score = 0\n",
    "loss = 0\n",
    "\n",
    "\n",
    "for e in range(epoch):\n",
    "    # At each epoch, we restart to a fresh game and get the initial state\n",
    "    state = env.reset()\n",
    "    # This assumes that the games will end\n",
    "    game_over = False\n",
    "\n",
    "    win = 0\n",
    "    lose = 0\n",
    "    \n",
    "    while not game_over:\n",
    "        # The agent performs an action\n",
    "        action = agent.act(state)\n",
    "\n",
    "        # Apply an action to the environment, get the next state, the reward\n",
    "        # and if the games end\n",
    "        prev_state = state\n",
    "        state, reward, game_over = env.act(action)\n",
    "\n",
    "        # Update the counters\n",
    "        if reward > 0:\n",
    "            win = win + reward\n",
    "        if reward < 0:\n",
    "            lose = lose -reward\n",
    "\n",
    "        # Apply the reinforcement strategy\n",
    "        loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
    "\n",
    "    # Save as a mp4\n",
    "    if e % 10 == 0:\n",
    "        env.draw(e)\n",
    "\n",
    "    # Update stats\n",
    "    score += win-lose\n",
    "\n",
    "    print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
    "          .format(e, epoch, loss, win, lose, win-lose))\n",
    "    agent.save()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The game, *eat cheese*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A rat runs on an island and tries to eat as much as possible. The island is subdivided into $N\\times N$ cells, in which there are cheese (+0.5) and poisonous cells (-1). The rat has a visibility of 2 cells (thus it can see $5^2$ cells). The rat is given a time $T$ to accumulate as much food as possible. It can perform 4 actions: going up, down, left, right. \n",
    "\n",
    "The goal is to code an agent to solve this task that will learn by trial and error. We propose the following environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment(object):\n",
    "    def __init__(self, grid_size=10, max_time=500, temperature=0.1):\n",
    "        grid_size = grid_size+4\n",
    "        self.grid_size = grid_size\n",
    "        self.max_time = max_time\n",
    "        self.temperature = temperature\n",
    "\n",
    "        #board on which one plays\n",
    "        self.board = np.zeros((grid_size,grid_size))\n",
    "        self.position = np.zeros((grid_size,grid_size))\n",
    "\n",
    "        # coordinate of the cat\n",
    "        self.x = 0\n",
    "        self.y = 1\n",
    "\n",
    "        # self time\n",
    "        self.t = 0\n",
    "\n",
    "        self.scale=16\n",
    "\n",
    "        self.to_draw = np.zeros((max_time+2, grid_size*self.scale, grid_size*self.scale, 3))\n",
    "\n",
    "\n",
    "    def draw(self,e):\n",
    "        skvideo.io.vwrite(str(e) + '.mp4', self.to_draw)\n",
    "\n",
    "    def get_frame(self,t):\n",
    "        b = np.zeros((self.grid_size, self.grid_size, 3)) + 128\n",
    "        b[self.board > 0, 0] = 256\n",
    "        b[self.board < 0, 2] = 256\n",
    "        b[self.x,self.y,:] = 256\n",
    "        b[-2:, :, :] = 0\n",
    "        b[:, -2:, :] = 0\n",
    "        b[:2, :, :] = 0\n",
    "        b[:, :2, :] = 0\n",
    "        \n",
    "        b =  cv2.resize(b, None, fx=self.scale, fy=self.scale, interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "        self.to_draw[t,:,:,:] = b\n",
    "\n",
    "\n",
    "    def act(self, action):\n",
    "        \"\"\"This function returns the new state, reward and decides if the\n",
    "        game ends.\"\"\"\n",
    "\n",
    "        self.get_frame(int(self.t))\n",
    "\n",
    "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
    "\n",
    "        self.position[0:2,:]= -1\n",
    "        self.position[:,0:2] = -1\n",
    "        self.position[-2:, :] = -1\n",
    "        self.position[:, -2:] = -1\n",
    "        #self.position[-2:, :] = -1\n",
    "\n",
    "        self.position[self.x, self.y] = 1\n",
    "        if action == 0:\n",
    "            if self.x == self.grid_size-3:\n",
    "                self.x = self.x-1\n",
    "            else:\n",
    "                self.x = self.x + 1\n",
    "        elif action == 1:\n",
    "            if self.x == 2:\n",
    "                self.x = self.x+1\n",
    "            else:\n",
    "                self.x = self.x-1\n",
    "        elif action == 2:\n",
    "            if self.y == self.grid_size - 3:\n",
    "                self.y = self.y - 1\n",
    "            else:\n",
    "                self.y = self.y + 1\n",
    "        elif action == 3:\n",
    "            if self.y == 2:\n",
    "                self.y = self.y + 1\n",
    "            else:\n",
    "                self.y = self.y - 1\n",
    "        else:\n",
    "            RuntimeError('Error: action not recognized')\n",
    "\n",
    "        self.t = self.t + 1\n",
    "        reward = self.board[self.x, self.y]\n",
    "        self.board[self.x, self.y] = 0\n",
    "        game_over = self.t > self.max_time\n",
    "        state = np.concatenate((self.board.reshape(self.grid_size, self.grid_size,1),\n",
    "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
    "        state = state[self.x-2:self.x+3,self.y-2:self.y+3,:]\n",
    "\n",
    "        return state, reward, game_over\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"This function resets the game and returns the initial state\"\"\"\n",
    "        \n",
    "        # random between min=3 and max= grid_size - 3\n",
    "        self.x = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
    "        self.y = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
    "\n",
    "        # Binom(1, temperature), size fois\n",
    "        bonus = 0.5 * np.random.binomial(1, self.temperature, size=self.grid_size**2)\n",
    "        bonus = bonus.reshape(self.grid_size,self.grid_size)\n",
    "\n",
    "        malus = -1.0 * np.random.binomial(1, self.temperature, size=self.grid_size**2)\n",
    "        malus = malus.reshape(self.grid_size, self.grid_size)\n",
    "\n",
    "        self.to_draw = np.zeros((self.max_time+2, self.grid_size*self.scale, self.grid_size*self.scale, 3))\n",
    "\n",
    "        # Pour ne pas avoir les malus aux mÃªmes positions que les bonus\n",
    "        malus[bonus>0]=0\n",
    "        \n",
    "        self.board = bonus + malus\n",
    "        self.board[self.x,self.y] = 0\n",
    "\n",
    "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
    "        self.position[0:2,:]= -1\n",
    "        self.position[:,0:2] = -1\n",
    "        self.position[-2:, :] = -1\n",
    "        #self.position[-2:, :] = -1\n",
    "        self.position[:, -2:] = -1\n",
    "        self.t = 0\n",
    "\n",
    "        state = np.concatenate((\n",
    "                               self.board.reshape(self.grid_size, self.grid_size,1),\n",
    "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
    "        state = state[self.x - 2:self.x + 3, self.y - 2:self.y + 3, :]\n",
    "        return state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following elements are important because they correspond to the hyper parameters for this project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "size = 13\n",
    "T=200\n",
    "temperature=0.3\n",
    "epochs_train=6 # set small when debugging\n",
    "epochs_test=6 # set small when debugging\n",
    "\n",
    "# display videos\n",
    "def display_videos(name):\n",
    "    video = io.open(name, 'r+b').read()\n",
    "    encoded = base64.b64encode(video)\n",
    "    return '''<video alt=\"test\" controls>\n",
    "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
    "             </video>'''.format(encoded.decode('ascii'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 2__ Explain the use of the arrays ```position``` and ```board```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I don't understand position. This code is shitty as hell.\n",
    "\n",
    "board is an array that will represent the current state of the game, which is : the cheese and poisounous trap left, and the position of the agent.\n",
    "\n",
    "position is an array of the same size keeping track of where the agent went (with 1), and where he can not go (with -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "__Question 3__ Implement a random Agent (only ```learned_act``` needs to be implemented):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomAgent(Agent):\n",
    "    def __init__(self):\n",
    "        super(RandomAgent, self).__init__()\n",
    "        pass\n",
    "\n",
    "    def learned_act(self, s):\n",
    "        random_action = np.random.randint(0, self.n_action)\n",
    "        # whether or not the action can be performed is checked by the act function\n",
    "        return random_action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "__Question 4__ Visualize the game moves. You need to fill in the following function for the evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(agent, env, epochs, prefix=''):\n",
    "    # Number of won games\n",
    "    score = 0\n",
    "    score = 0\n",
    "    loss = 0\n",
    "    \n",
    "    for e in range(epochs):\n",
    "        \n",
    "        ##### FILL IN HERE\n",
    "        # At each epoch, we restart to a fresh game and get the initial state\n",
    "        state = env.reset()\n",
    "        # This assumes that the games will end\n",
    "        game_over = False\n",
    "\n",
    "        win = 0\n",
    "        lose = 0\n",
    "        \n",
    "        while not game_over:\n",
    "            # The agent performs an action\n",
    "            action = agent.act(state)\n",
    "\n",
    "            # Apply an action to the environment, get the next state, the reward\n",
    "            # and if the games end\n",
    "            prev_state = state\n",
    "            state, reward, game_over = env.act(action)\n",
    "\n",
    "            # Update the counters\n",
    "            if reward > 0:\n",
    "                win = win + reward\n",
    "            if reward < 0:\n",
    "                lose = lose -reward\n",
    "\n",
    "            # Apply the reinforcement strategy\n",
    "            ## No reinforcement strategy for a random Agent\n",
    "            ## loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
    "        \n",
    "        # Save as a mp4\n",
    "        env.draw(prefix+str(e))\n",
    "\n",
    "        # Update stats\n",
    "        score = score + win-lose\n",
    "\n",
    "        print(\"Win/lose count {}/{}. Average score ({})\"\n",
    "              .format(win, lose, score/(1+e)))\n",
    "    print('Final score: '+str(score/epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/ffmpeg -y -f rawvideo -pix_fmt rgb24 -s 272x272 -i - /home/johnny/3A/deeplearning/rl_project/random0.mp4\n",
      "Win/lose count 8.5/15.0. Average score (-6.5)\n",
      "/usr/bin/ffmpeg -y -f rawvideo -pix_fmt rgb24 -s 272x272 -i - /home/johnny/3A/deeplearning/rl_project/random1.mp4\n",
      "Win/lose count 9.5/3.0. Average score (0.0)\n",
      "/usr/bin/ffmpeg -y -f rawvideo -pix_fmt rgb24 -s 272x272 -i - /home/johnny/3A/deeplearning/rl_project/random2.mp4\n",
      "Win/lose count 14.0/15.0. Average score (-0.3333333333333333)\n",
      "/usr/bin/ffmpeg -y -f rawvideo -pix_fmt rgb24 -s 272x272 -i - /home/johnny/3A/deeplearning/rl_project/random3.mp4\n",
      "Win/lose count 14.0/23.0. Average score (-2.5)\n",
      "/usr/bin/ffmpeg -y -f rawvideo -pix_fmt rgb24 -s 272x272 -i - /home/johnny/3A/deeplearning/rl_project/random4.mp4\n",
      "Win/lose count 13.0/14.0. Average score (-2.2)\n",
      "/usr/bin/ffmpeg -y -f rawvideo -pix_fmt rgb24 -s 272x272 -i - /home/johnny/3A/deeplearning/rl_project/random5.mp4\n",
      "Win/lose count 7.5/8.0. Average score (-1.9166666666666667)\n",
      "Final score: -1.9166666666666667\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" controls>\n",
       "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the game\n",
    "env = Environment(grid_size=size, max_time=T,temperature=temperature)\n",
    "\n",
    "# Initialize the agent!\n",
    "agent = RandomAgent()\n",
    "\n",
    "test(agent,env,epochs_test,prefix='random')\n",
    "HTML(display_videos('random0.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## DQN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us assume here that $T=\\infty$.\n",
    "\n",
    "***\n",
    "__Question 5__ Let $\\pi$ be a policy, show that:\n",
    "\n",
    "\\begin{equation*}\n",
    "Q^{\\pi}(s,a)=E_{(s',a')\\sim p(.|s,a)}[r(s,a)+\\gamma Q^{\\pi}(s',a')]\n",
    "\\end{equation*}\n",
    "\n",
    "Then, show that for the optimal policy $\\pi^*$ (we assume its existence), the following holds: \n",
    "\n",
    "\\begin{equation*}\n",
    "Q^{*}(s,a)=E_{s'\\sim \\pi^*(.|s,a)}[r(s,a)+\\gamma\\max_{a'}Q^{*}(s',a')].\n",
    "\\end{equation*}\n",
    "Finally, deduce that a plausible objective is:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\mathcal{L}(\\theta)=E_{s' \\sim \\pi^*(.|s,a)}\\Vert r+\\gamma\\max_{a'}Q(s',a',\\theta)-Q(s,a,\\theta)\\Vert^{2}.\n",
    "\\end{equation*}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "====================================================================================================================================================================================================================================\n",
    "\n",
    "First, let's start off from the relation : \n",
    "    $$ Q^{\\pi}(s, a) = E^{\\pi}( G_{t} | S_t = s, A_t = a) $$\n",
    "\n",
    "Using the cumulative reward $G_t$ property:\n",
    "    $$ Q^{\\pi}(s, a) = E^{\\pi}( R_{t+1} + \\gamma * G_{t + 1} | S_t = s, A_t = a) $$\n",
    "\n",
    "$R_{t+1}$ is the reward at step t+1 (after state $S_t$ and action $A_t$)\n",
    "\n",
    "Separating the expectation:\n",
    "    $$ Q^{\\pi}(s, a) = E^{\\pi}( R_{t+1} | S_t = s, A_t = a) + E^{\\pi}(\\gamma * G_{t + 1} | S_t = s, A_t = a) $$\n",
    "\n",
    "By definition : $r(s,a) = (R_{t+1} | S_t = s, A_t = a)$\n",
    "So the first term is : $E^{\\pi}( R_{t+1} | S_t = s, A_t = a) = E^{\\pi}(r(s,a))$\n",
    "\n",
    "As for the second term :\n",
    "$G_{t + 1}$ is independant of $(S_t = s, A_t = a)$. Because $G_{t + 1}$ is the cumulative reward at step t+1, and therefore does not care about the state $S_t$, only the current one $S_{t+1}$. So we have:\n",
    "    $$E^{\\pi}(\\gamma * G_{t + 1} | S_t = s, A_t = a) = E^{\\pi}(\\gamma * G_{t + 1})$$ \n",
    "\n",
    "Then using the property the expectation:\n",
    "    $$E^{\\pi}(\\gamma * G_{t + 1}) = E^{\\pi}(E^{\\pi}(\\gamma * G_{t + 1} | S_{t+1} = s', A_{t+1} = a')) $$\n",
    "\n",
    "And the expression that we've made appear is:\n",
    "    $$E^{\\pi}(\\gamma * G_{t + 1} | S_{t+1} = s', A_{t+1} = a') = Q^{\\pi}(s', a')$$\n",
    "So \n",
    "    $$ E^{\\pi}(E^{\\pi}(\\gamma * G_{t + 1} | S_{t+1} = s', A_{t+1} = a')) =  E^{\\pi}(Q^{\\pi}(s', a'))$$\n",
    "This is our second term.\n",
    "\n",
    "Then if we replace everything:\n",
    "    $$ Q^{\\pi}(s, a) = E^{\\pi}(r(s,a)) + E^{\\pi}(Q^{\\pi}(s', a')) $$\n",
    "Since $(s, a)$ are fixed, the expectation is acting on $(s', a')$\n",
    "\n",
    "\n",
    "====================================================================================================================================================================================================================================\n",
    "\n",
    "If we assume the existence of an optimal policy giving us the optimal action-value function:\n",
    "    $$ Q^*(s,a) = max_{\\pi} Q^{\\pi}(s,a) $$\n",
    "\n",
    "Then it is sure that the policy is always a greedy one, that is always taking the action giving the best reward.\n",
    "    $$Q^*(s, a) = E_{s' ~ \\pi^*(. |s, a)} (r(s,a) + \\gamma max_{a'}Q^*(s',a'))$$\n",
    "We have this expression because we are always taking the best reward.\n",
    "\n",
    "====================================================================================================================================================================================================================================\n",
    "\n",
    "The real $Q^*$ is not available to us, so the idea is to approach it dynamically by updating its values step by step using a neural network. If we take the loss:\n",
    "    $$ \\mathcal{L}(\\theta)=E_{s' \\sim \\pi^*(.|s,a)}\\Vert r+\\gamma\\max_{a'}Q(s',a',\\theta)-Q(s,a,\\theta)\\Vert^{2}.$$\n",
    "    \n",
    "And derivate it wrt $\\theta$:\n",
    "    $$ \\frac{\\partial \\mathcal{L}}{\\partial \\theta} = E_{s' \\sim \\pi^*(.|s,a)}(2(r+\\gamma\\max_{a'}Q(s',a',\\theta)-Q(s,a,\\theta))*(\\gamma \\frac{\\partial \\max_{a'}Q(s',a',\\theta)}{\\partial \\theta} - \\frac{\\partial Q(s,a,\\theta)}{\\partial \\theta})) = 0.$$\n",
    "    \n",
    "By equallying to 0: \n",
    "    $$ (r+\\gamma\\max_{a'}Q(s',a',\\theta)-Q(s,a,\\theta))*(\\gamma \\frac{\\partial \\max_{a'}Q(s',a',\\theta)}{\\partial \\theta} - \\frac{\\partial Q(s,a,\\theta)}{\\partial \\theta}) = 0 \\text{  almost sure}\n",
    " $$\n",
    " \n",
    " $\\frac{\\partial \\max_{a'}Q(s',a',\\theta)}{\\partial \\theta}$ is equal to 0, and $\\frac{\\partial Q(s,a,\\theta)}{\\partial \\theta}$ is unlikely to be equal to 0\n",
    " \n",
    " Therefore, we have:\n",
    "     $$ (r+\\gamma\\max_{a'}Q(s',a',\\theta)-Q(s,a,\\theta)) = 0 \\text{  almost sure} $$\n",
    " \n",
    " By definition, the Q founded as such is the $Q^*$ that we are looking for."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "The DQN-learning algorithm relies on these derivations to train the parameters $\\theta$ of a Deep Neural Network:\n",
    "\n",
    "1. At the state $s_t$, select the action $a_t$ with best reward using $Q_t$ and store the results;\n",
    "\n",
    "2. Obtain the new state $s_{t+1}$ from the environment $p$;\n",
    "\n",
    "3. Store $(s_t,a_t,s_{t+1})$;\n",
    "\n",
    "4. Obtain $Q_{t+1}$ by minimizing  $\\mathcal{L}$ from a recovered batch from the previously stored results.\n",
    "\n",
    "***\n",
    "__Question 6__ Implement the class ```Memory``` that stores moves (in a replay buffer) via ```remember``` and provides a ```random_access``` to these. Specify a maximum memory size to avoid side effects. You can for example use a ```list()``` and set by default ```max_memory=100```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Memory(object):\n",
    "    def __init__(self, max_size=100):\n",
    "        self.max_size = max_size\n",
    "        self.memory = list()\n",
    "    def is_full(self):\n",
    "        return len(self.memory) >= self.max_size\n",
    "    \n",
    "    def remember(self, move):\n",
    "        # move should a tuple (s_t, s_t+1, action, reward, game_over)\n",
    "        if self.is_full():\n",
    "            self.memory.pop(0)\n",
    "        self.memory.append(move)\n",
    "\n",
    "    def random_access(self):\n",
    "        n = len(self.memory)\n",
    "        random_index = np.random.randint(0, n)\n",
    "        return self.memory[random_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "The pipeline we will use for training is given below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(agent,env,epoch,prefix=''):\n",
    "    # Number of won games\n",
    "    score = 0\n",
    "    loss = 0\n",
    "\n",
    "    for e in range(epoch):\n",
    "        # At each epoch, we restart to a fresh game and get the initial state\n",
    "        state = env.reset()\n",
    "        # This assumes that the games will terminate\n",
    "        game_over = False\n",
    "\n",
    "        win = 0\n",
    "        lose = 0\n",
    "\n",
    "        while not game_over:\n",
    "            # The agent performs an action\n",
    "            action = agent.act(state)\n",
    "\n",
    "            # Apply an action to the environment, get the next state, the reward\n",
    "            # and if the games end\n",
    "            prev_state = state\n",
    "            state, reward, game_over = env.act(action)\n",
    "\n",
    "            # Update the counters\n",
    "            if reward > 0:\n",
    "                win = win + reward\n",
    "            if reward < 0:\n",
    "                lose = lose -reward\n",
    "\n",
    "            # Apply the reinforcement strategy\n",
    "            loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
    "\n",
    "        # Save as a mp4\n",
    "        if e % 10 == 0:\n",
    "            env.draw(prefix+str(e))\n",
    "\n",
    "        # Update stats\n",
    "        score += win-lose\n",
    "\n",
    "        print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
    "              .format(e, epoch, loss, win, lose, win-lose))\n",
    "        agent.save(name_weights=prefix+'model.h5',name_model=prefix+'model.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "__Question 7__ Implement the DQN training algorithm using a cascade of fully connected layers. You can use different learning rate, batch size or memory size parameters. In particular, the loss might oscillate while the player will start to win the games. You have to find a good criterium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_input_model(state, action, n_action=4):\n",
    "    x, y, z = np.shape(state)\n",
    "#     input_states = np.zeros((x, y, z, n_action))\n",
    "#     input_states[:, :, :, action] = state\n",
    "    input_states = np.zeros((x, y, z))\n",
    "    input_states[:, :, :] = state\n",
    "    return input_states\n",
    "\n",
    "class DQN(Agent):\n",
    "    def __init__(self, grid_size,  epsilon = 0.1, memory_size=100, batch_size = 16,n_state=2, discount = 0.99):\n",
    "        super(DQN, self).__init__(epsilon = epsilon)\n",
    "\n",
    "        # Discount for Q learning\n",
    "        self.discount = discount\n",
    "        \n",
    "        self.grid_size = grid_size\n",
    "        \n",
    "        # number of state\n",
    "        self.n_state = n_state\n",
    "\n",
    "        # Memory\n",
    "        self.memory = Memory(memory_size)\n",
    "        \n",
    "        # Batch size when learning\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def learned_act(self, s):\n",
    "        greedy_action, max_Q = self.argmax_Q(s)\n",
    "        return greedy_action\n",
    "\n",
    "    def reinforce(self, state, next_state, action, reward, game_over):\n",
    "        # Two steps: first memorize the states, second learn from the pool\n",
    "\n",
    "        self.memory.remember([state, next_state, action, reward, game_over])\n",
    "        \n",
    "        # 5 x 5 is the shape of a state\n",
    "        # self.n_state = 2 is the dimension of the input of a state[i, j] \n",
    "        # giving (value in {0, -1, 0.5}, is_accessible in {0, -1})\n",
    "        \n",
    "        input_states = np.zeros((self.batch_size, 5, 5, self.n_state))\n",
    "        # 4 is the number of actions possible, so target_Q isnt the max, but all Q possibles ? \n",
    "        target_q = np.zeros((self.batch_size, 4))\n",
    "        \n",
    "        for i in range(self.batch_size):\n",
    "            ######## FILL IN\n",
    "            memory_state, memory_next_state, memory_action, memory_reward, memory_game_over = self.memory.random_access()\n",
    "                \n",
    "            input_states[i, :, :, :] = memory_state\n",
    "            target_q[i, :] = self.Q(memory_state)\n",
    "            \n",
    "            if memory_game_over: # or memory_game_over ?\n",
    "                target_q[i][memory_action] = memory_reward\n",
    "            else:\n",
    "                ######## FILL IN\n",
    "                target_q[i][memory_action] = memory_reward + self.discount * self.max_Q(memory_next_state)\n",
    "        # HINT: Clip the target to avoid exploiding gradients.. -- clipping is a bit tighter\n",
    "        target_q = np.clip(target_q, -3, 3)\n",
    "\n",
    "        l = self.model.train_on_batch(input_states, target_q)\n",
    "        return l\n",
    "    \n",
    "    def max_Q(self, state):\n",
    "        arg_max, max_Q = self.argmax_Q(state)\n",
    "        return max_Q\n",
    "    \n",
    "    def argmax_Q(self, state):\n",
    "        #available_actions = self.available_actions(state)\n",
    "        Q_values = self.Q(state)[0] # self.Q() will return a 1 x 4 array of arrays.\n",
    "        arg_max = np.argmax(Q_values)\n",
    "        Q_values[arg_max]\n",
    "        return (arg_max, Q_values[arg_max])\n",
    "    \n",
    "    def Q(self, state):\n",
    "        return self.model.predict(np.array([state]))\n",
    "\n",
    "    def save(self,name_weights='model.h5',name_model='model.json'):\n",
    "        self.model.save_weights(name_weights, overwrite=True)\n",
    "        with open(name_model, \"w\") as outfile:\n",
    "            json.dump(self.model.to_json(), outfile)\n",
    "            \n",
    "    def load(self,name_weights='model.h5',name_model='model.json'):\n",
    "        with open(name_model, \"r\") as jfile:\n",
    "            model = model_from_json(json.load(jfile))\n",
    "        model.load_weights(name_weights)\n",
    "        model.compile(\"sgd\", \"mse\")\n",
    "        self.model = model\n",
    "\n",
    "            \n",
    "class DQN_FC(DQN):\n",
    "    def __init__(self, *args, lr=0.1, momentum=0.0, **kwargs):\n",
    "        super(DQN_FC, self).__init__( *args,**kwargs)\n",
    "        \n",
    "        # NN Model\n",
    "        \n",
    "        ####### FILL IN\n",
    "        \n",
    "        model = Sequential()\n",
    "        model.add(Reshape((50, ), input_shape = (5, 5, 2)))\n",
    "        model.add(Dense(30, activation=\"relu\"))\n",
    "        model.add(Dense(20, activation=\"relu\"))\n",
    "        model.add(Dense(4))\n",
    "        \n",
    "        model.compile(SGD(lr=lr, decay=1e-4, momentum=momentum), \"mse\")\n",
    "        self.model = model\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000/021 | Loss 0.0003 | Win/lose count 1.5/5.0 (-3.5)\n",
      "Epoch 001/021 | Loss 0.0017 | Win/lose count 2.0/7.0 (-5.0)\n",
      "Epoch 002/021 | Loss 0.0072 | Win/lose count 8.5/8.0 (0.5)\n",
      "Epoch 003/021 | Loss 0.0033 | Win/lose count 2.5/0 (2.5)\n",
      "Epoch 004/021 | Loss 0.0059 | Win/lose count 3.5/2.0 (1.5)\n",
      "Epoch 005/021 | Loss 0.0020 | Win/lose count 7.0/1.0 (6.0)\n",
      "Epoch 006/021 | Loss 0.0092 | Win/lose count 3.5/4.0 (-0.5)\n",
      "Epoch 007/021 | Loss 0.0019 | Win/lose count 5.5/5.0 (0.5)\n",
      "Epoch 008/021 | Loss 0.0037 | Win/lose count 4.0/2.0 (2.0)\n",
      "Epoch 009/021 | Loss 0.0045 | Win/lose count 10.5/3.0 (7.5)\n",
      "Epoch 010/021 | Loss 0.0034 | Win/lose count 6.0/2.0 (4.0)\n",
      "Epoch 011/021 | Loss 0.0080 | Win/lose count 7.0/9.0 (-2.0)\n",
      "Epoch 012/021 | Loss 0.0106 | Win/lose count 14.0/6.0 (8.0)\n",
      "Epoch 013/021 | Loss 0.0049 | Win/lose count 7.0/6.0 (1.0)\n",
      "Epoch 014/021 | Loss 0.0056 | Win/lose count 8.0/5.0 (3.0)\n",
      "Epoch 015/021 | Loss 0.0080 | Win/lose count 12.0/3.0 (9.0)\n",
      "Epoch 016/021 | Loss 0.0095 | Win/lose count 14.5/4.0 (10.5)\n",
      "Epoch 017/021 | Loss 0.0026 | Win/lose count 15.5/1.0 (14.5)\n",
      "Epoch 018/021 | Loss 0.0070 | Win/lose count 10.0/2.0 (8.0)\n",
      "Epoch 019/021 | Loss 0.0058 | Win/lose count 11.5/2.0 (9.5)\n",
      "Epoch 020/021 | Loss 0.0089 | Win/lose count 16.5/2.0 (14.5)\n"
     ]
    }
   ],
   "source": [
    "size = 13\n",
    "T=200\n",
    "temperature=0.3\n",
    "epochs_train=21 # set small when debugging\n",
    "epochs_test=21 # set small when debugging\n",
    "\n",
    "env = Environment(grid_size=size, max_time=T, temperature=0.3)\n",
    "agent = DQN_FC(size, lr=.1, momentum=0.9, epsilon = 0.1, memory_size=2000, batch_size = 32, discount=0.9)\n",
    "train(agent, env, epochs_train, prefix='fc_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" controls>\n",
       "                <source src=\"data:video/mp4;base64,AAAAIGZ0eXBpc29tAAACAGlzb21pc28yYXZjMW1wNDEAAAAIZnJlZQAAFuRtZGF0AAACrQYF//+p3EXpvebZSLeWLNgg2SPu73gyNjQgLSBjb3JlIDE1MiByMjg1NCBlOWE1OTAzIC0gSC4yNjQvTVBFRy00IEFWQyBjb2RlYyAtIENvcHlsZWZ0IDIwMDMtMjAxNyAtIGh0dHA6Ly93d3cudmlkZW9sYW4ub3JnL3gyNjQuaHRtbCAtIG9wdGlvbnM6IGNhYmFjPTEgcmVmPTMgZGVibG9jaz0xOjA6MCBhbmFseXNlPTB4MToweDExMSBtZT1oZXggc3VibWU9NyBwc3k9MSBwc3lfcmQ9MS4wMDowLjAwIG1peGVkX3JlZj0xIG1lX3JhbmdlPTE2IGNocm9tYV9tZT0xIHRyZWxsaXM9MSA4eDhkY3Q9MCBjcW09MCBkZWFkem9uZT0yMSwxMSBmYXN0X3Bza2lwPTEgY2hyb21hX3FwX29mZnNldD00IHRocmVhZHM9OCBsb29rYWhlYWRfdGhyZWFkcz0xIHNsaWNlZF90aHJlYWRzPTAgbnI9MCBkZWNpbWF0ZT0xIGludGVybGFjZWQ9MCBibHVyYXlfY29tcGF0PTAgY29uc3RyYWluZWRfaW50cmE9MCBiZnJhbWVzPTMgYl9weXJhbWlkPTIgYl9hZGFwdD0xIGJfYmlhcz0wIGRpcmVjdD0xIHdlaWdodGI9MSBvcGVuX2dvcD0wIHdlaWdodHA9MiBrZXlpbnQ9MjUwIGtleWludF9taW49MjUgc2NlbmVjdXQ9NDAgaW50cmFfcmVmcmVzaD0wIHJjX2xvb2thaGVhZD00MCByYz1jcmYgbWJ0cmVlPTEgY3JmPTIzLjAgcWNvbXA9MC42MCBxcG1pbj0wIHFwbWF4PTY5IHFwc3RlcD00IGlwX3JhdGlvPTEuNDAgYXE9MToxLjAwAIAAAALDZYiEADP//vaG+BTYUyP+T7/8I/+5H7cfWfrixkIJvrVeQ9GAMl8a/5lGYaXpyc8t7R+vTNAEZz8ZS8pY/so8NlBOhlWbQ+BTV0ni+BSUKX43zXRcxqy9tXk/+Z5/drTInVVaRMhEdne/qGtY8t7T2UoImHawRquSt2Vre9PPvFyaA2lHbcvNI8BVACN8xeYpjxvcONHHUf3jguIk5Xw3buApR1F6w7W2wnOeW9SSqjHcSMKXgB+9WD6wo+cAgDB4bxv06sFt6jLqY8eAH2G6u82vaJFoBzmM5Vx3lHt0KqfXH9Bx5UxZU6aCZN4A5lfinRtG2BrT9UG2oaTI00vcgSj6ZUPbUgAmdeWCEkG3RRm+GB/VSQAVgiUzBuGKAgk1HGe+T99FiS9i4ZV/c8HF6SKwC+FkoYuCfofCG7nSYloQH1ECCHHIf4EynWdVjwlS/uBB8NAi7OuW+djszqo5kt+5xZoJGm94MAD7BY9juMX+wnC4CdJmPUBs4DkgHtoUt2Le+eENXHRnEBM+BF2lTwIuYLzMRTN3T55is/46ntbqmQAiV5NWIEgAPJYru8wxpEgmW75FhbUlVG+JlSZIEPviIpxZvAE9aIDp6Y3dGMCk7j/YwAAqtFbLF156BeEPm+zVIzF3dkS8v2Sct93TDkJKDI6bLYFc3J9WDXD6O/kWhHFwL9jSX2y3Xg3sWhO50VrFg347uRt1oQSLQxPyFiDICV91rTUerLZ3MC8W8WAtOOhoo60OsQb8WSiQYlkrYrVlBSg83Yd5baPrCTONMHJV1lm+hYhXkf2XudriHendN/n0YgBtjrSLALzAhvTkpsHJDs3bkAaes8q8oU7pg99hquqQhgsWPAHKGLFYB8+3v2RFshXpAMg4NEK3+n7pnKqvHP97yhMAJ3Zx7gE7a/QwUNt9JCHPUNXlezZ6rPAAAy8AAAAYQZohbEM//p4QAcQSDXOVW4OYiI/v5jy8AAAAF0GaQjwhkymEM//+nhABzvXGtNdgy291AAAAGEGaY0nhDyZTAhn//p4QAdn1xt7033W3pgAAABlBmoRJ4Q8mUwIb//6nhAB8AeFOs6fdbeOBAAAAHkGapknhDyZTBRE8M//+nhAB5/X39CugD3XEfWbcXQAAAA8BnsVqQr8AZwlpUigSqf8AAAAZQZrHSeEPJlMCG//+p4QAT/3U/UcaEhxUwQAAABlBmuhJ4Q8mUwIb//6nhAAzvsH+E4LdCW9AAAAAG0GbC0nhDyZTAhv//qeEACDfHT3wzxNBbpDYEAAAABJBnylFETwr/wAbAjtzrJ8nV4EAAAAOAZ9KakK/ABsLELvepbMAAAAdQZtNSahBaJlMFPDf/qeEABY/dT7vNzk8DwbpDj4AAAAQAZ9sakK/ABHc0bzTFW1mwQAAAB1Bm29J4QpSZTBSwz/+nhAAN36+/oV0Ae64j6zf3QAAAA8Bn45qQr8AC6Nt0o0h4+sAAAAZQZuQSeEOiZTAhv/+p4QACPfHT6jjQkPdwAAAAB5Bm7JJ4Q8mUwUVPDf//qeEAAiqXtZk79g/qwecn0AAAAAQAZ/RakK/AAcVnzG6HJB5uQAAAB5Bm9RJ4Q8mUwU8M//+nhAAM2vuuI5/SOvv2jLaznAAAAAQAZ/zakK/AArNkQm4z69WeAAAABhBm/VJ4Q8mUwIb//6nhAANP7B69mfBFwkAAAAZQZoWSeEPJlMCG//+p4QADO+wf4Tgt0KuwAAAAB1BmjpJ4Q8mUwIb//6nhAAIN8dPutLM1NufebWL+QAAABBBnlhFETwv/wAE+ZYqBZNHAAAAEAGed3RCvwAGwAUzyvyU5+gAAAAPAZ55akK/AAR4NA8mCZOBAAAAGkGae0moQWiZTAhv//6nhAAIagCzbbPs+fPAAAAAEUGan0nhClJlMCG//qeEAAEnAAAAE0GevUU0TC//AAfvdumcV1PYnq0AAAAQAZ7cdEK/AAsWWqB07UQSgAAAAA8Bnt5qQr8ACxNt0o0h4/8AAAAZQZrCSahBaJlMCGf//p4QADNyGOfw5zfXvwAAABJBnuBFESwr/wAKzY8CEjH760AAAAAOAZ8BakK/AArNj10/VlsAAAAbQZsDSahBbJlMCGf//p4QAE94Mc/hz4gcP8NbAAAAF0GbJEnhClJlMCGf/p4QAHlKcc/S/uXBAAAAGkGbRUnhDomUwIZ//p4QAHn+D4Cmc63QMkSNAAAAGEGbZknhDyZTAhn//p4QAHc9/d2nN3FwpwAAABlBm4dJ4Q8mUwIb//6nhAAufon+q3zH4kfBAAAAG0GbqknhDyZTAhn//p4QALnwZS3SC5uM4nyvZgAAABFBn8hFETwr/wAmuaN5oWD81wAAAA4Bn+lqQr8AJrKMZNyVrwAAABlBm+tJqEFomUwIZ//+nhAAsfumxlybKt8EAAAAGEGaDEnhClJlMCGf/p4QAQU4Rz+HOb60TgAAABlBmi1J4Q6JlMCG//6nhABpaRP9VvmPxD5hAAAAGEGaTknhDyZTAhv//qeEAGn9g9ezPgivSQAAABlBmm9J4Q8mUwId//6plgA0HtLwtQT+wELBAAAAFkGak0nhDyZTAhv//qeEAJt8dPtcsoAAAAAOQZ6xRRE8L/8AXRlQMCAAAAAQAZ7QdEK/AHxsVi8/gckXwQAAAA8BntJqQr8AVBRogtR5dd0AAAAeQZrXSahBaJlMCG///qeEAGT9g/zyCtUyEg1LnDKYAAAAFUGe9UURLC//ADtfxXCOVo/XIrUPMQAAABABnxR0Qr8AUdNaMkt/rfzAAAAAEAGfFmpCvwA2DqnkuZ8lK4EAAAAaQZsYSahBbJlMCG///qeEAEG+On1HGhIcZUEAAAAZQZs5SeEKUmUwId/+qZYAFd99X12INxUUcAAAABZBm11J4Q6JlMCHf/6plgAOT7S/q6fBAAAADkGfe0URPC//ABDaAFggAAAAEAGfmnRCvwAXS0d0dt8LeYEAAAAPAZ+cakK/ABZ7KN1nqz69AAAAE0GbgUmoQWiZTAh3//6plgAAlYAAAAAMQZ+/RREsL/8AALKAAAAADwGf3nRCvwAWeyjiOy7LfwAAAA8Bn8BqQr8AF0UaILUeXrMAAAATQZvFSahBbJlMCHf//qmWAACVgQAAAAxBn+NFFSwv/wAAsoAAAAAPAZ4CdEK/ABZ7KOI7Lst/AAAADwGeBGpCvwAWeyjdZ6s+vQAAABxBmglJqEFsmUwId//+qZYAFS0s5QZoFPox+mWnAAAAEEGeJ0UVLC//ABkhHGdyr6EAAAAQAZ5GdEK/ACG+okT4sxSAEAAAAA8BnkhqQr8AIq80TUlOaYAAAAATQZpNSahBbJlMCHf//qmWAACVgQAAAAxBnmtFFSwv/wAAsoAAAAAPAZ6KdEK/ACFKkcR2XZZbAAAADwGejGpCvwAirzRBajy8PwAAABNBmpFJqEFsmUwId//+qZYAAJWBAAAADEGer0UVLC//AACygQAAAA8Bns50Qr8AIruO6O2+FlMAAAAPAZ7QakK/ACKvNEFqPLw+AAAAE0Ga1UmoQWyZTAh3//6plgAAlYEAAAAMQZ7zRRUsL/8AALKAAAAADwGfEnRCvwAiu47o7b4WUwAAAA8BnxRqQr8AIq80QWo8vD8AAAATQZsZSahBbJlMCHf//qmWAACVgAAAAAxBnzdFFSwv/wAAsoEAAAAPAZ9WdEK/ACK7jujtvhZTAAAADwGfWGpCvwAirzRBajy8PgAAABNBm11JqEFsmUwId//+qZYAAJWBAAAADEGfe0UVLC//AACygAAAAA8Bn5p0Qr8AIruO6O2+FlMAAAAPAZ+cakK/ACKvNEFqPLw/AAAAE0GbgUmoQWyZTAh3//6plgAAlYAAAAAMQZ+/RRUsL/8AALKAAAAADwGf3nRCvwAiu47o7b4WUwAAAA8Bn8BqQr8AIq80QWo8vD4AAAATQZvFSahBbJlMCHf//qmWAACVgQAAAAxBn+NFFSwv/wAAsoAAAAAPAZ4CdEK/ACK7jujtvhZTAAAADwGeBGpCvwAirzRBajy8PwAAABNBmglJqEFsmUwId//+qZYAAJWBAAAADEGeJ0UVLC//AACygQAAAA8BnkZ0Qr8AIruO6O2+FlMAAAAPAZ5IakK/ACKvNEFqPLw+AAAAE0GaTUmoQWyZTAh3//6plgAAlYEAAAAMQZ5rRRUsL/8AALKAAAAADwGeinRCvwAiu47o7b4WUwAAAA8BnoxqQr8AIq80QWo8vD8AAAATQZqRSahBbJlMCHf//qmWAACVgQAAAAxBnq9FFSwv/wAAsoEAAAAPAZ7OdEK/ACK7jujtvhZTAAAADwGe0GpCvwAirzRBajy8PgAAABNBmtVJqEFsmUwId//+qZYAAJWBAAAADEGe80UVLC//AACygAAAAA8BnxJ0Qr8AIruO6O2+FlMAAAAPAZ8UakK/ACKvNEFqPLw/AAAAHEGbGUmoQWyZTAh3//6plgAhBR0QLNAd30Y9cZIAAAAQQZ83RRUsL/8AJ8ywT438wQAAAA8Bn1Z0Qr8ANhJZuDZLx3EAAAAPAZ9YakK/ADYWIHkwRheAAAAAEkGbXUmoQWyZTAhv//6nhAABJwAAAAxBn3tFFSwv/wAAsoAAAAAQAZ+adEK/ADV5ycR2XZXZgQAAAA8Bn5xqQr8ANXnJus9We3cAAAASQZuBSahBbJlMCG///qeEAAEnAAAADEGfv0UVLC//AACygAAAABABn950Qr8ANXnJxHZdldmBAAAADwGfwGpCvwA1ecm6z1Z7dwAAABlBm8JJqEFsmUwIb//+p4QAQ0fMeRif5bdxAAAAGUGb5UnhClJlMCG//qeEAEO+On1HGhIcYsAAAAASQZ4DRTRMK/8AOKrg1x73qPaBAAAADgGeJGpCvwA4oMx6IrjbAAAAHEGaJ0moQWiZTBTw3/6nhAAsfup+5kYWzFCOYlUAAAAPAZ5GakK/ACOyt0o0h4snAAAAEUGaS0nhClJlMCGf/p4QAAR8AAAADEGeaUU0TC//AACygAAAAA8Bnoh0Qr8AFnso4jsuy38AAAAPAZ6KakK/ABZ7KN1nqz69AAAAGUGajEmoQWiZTAhn//6eEABsfX3dpzdxcPwAAAAZQZqtSeEKUmUwIb/+p4QAGx9g/wnBboTqQQAAABlBms5J4Q6JlMCG//6nhAARb46fUcaEh2BBAAAAHkGa8UnhDyZTAhv//qeEAAuvup93m6xwR4yEUJEmgwAAABJBnw9FETwr/wAJbmjeaYqnLa8AAAAPAZ8wakK/AAlsrdKNIeRGAAAAF0GbM0moQWiZTBTw7/6plgACY/Rz8oJhAAAAEAGfUmpCvwAF5zk72ePue4AAAAAlQZtXSeEKUmUwIb/+p4QADE+7fzLK8YZ+BTLZ2fAoUltfmy6VOAAAABJBn3VFNEwv/wAHQT1mCznvZ3EAAAAPAZ+UdEK/AAlvpO4NkvOGAAAAEAGflmpCvwAJ9YR5LmfKBoEAAAAaQZuYSahBaJlMCHf//qmWAAYz2l/O6QphLREAAAAdQZu8SeEKUmUwId/+qZYAA+vtL+xYDogW4m0ucrIAAAAQQZ/aRTRML/8ABLaA5dmTVwAAABABn/l0Qr8ABnAFM8r8lOiYAAAAEAGf+2pCvwAGmSti9XYc9EEAAAATQZvgSahBaJlMCHf//qmWAACVgQAAAAxBnh5FESwv/wAAsoAAAAAQAZ49dEK/AAaayrur8d424AAAABABnj9qQr8ABpkrYvV2HPRBAAAAE0GaJEmoQWyZTAh3//6plgAAlYAAAAAMQZ5CRRUsL/8AALKBAAAAEAGeYXRCvwAGmsq7q/HeNuAAAAAQAZ5jakK/AAaZK2L1dhz0QQAAABNBmmhJqEFsmUwId//+qZYAAJWBAAAADEGehkUVLC//AACygQAAABABnqV0Qr8ABprKu6vx3jbhAAAAEAGep2pCvwAGmSti9XYc9EAAAAATQZqsSahBbJlMCHf//qmWAACVgAAAAAxBnspFFSwv/wAAsoEAAAAQAZ7pdEK/AAaayrur8d424AAAABABnutqQr8ABpkrYvV2HPRAAAAAE0Ga8EmoQWyZTAh3//6plgAAlYEAAAAMQZ8ORRUsL/8AALKBAAAAEAGfLXRCvwAGmsq7q/HeNuEAAAAQAZ8vakK/AAaZK2L1dhz0QAAAABNBmzRJqEFsmUwId//+qZYAAJWAAAAADEGfUkUVLC//AACygQAAABABn3F0Qr8ABprKu6vx3jbgAAAAEAGfc2pCvwAGmSti9XYc9EAAAAATQZt4SahBbJlMCHf//qmWAACVgQAAAAxBn5ZFFSwv/wAAsoAAAAAQAZ+1dEK/AAaayrur8d424QAAABABn7dqQr8ABpkrYvV2HPRBAAAAE0GbvEmoQWyZTAh3//6plgAAlYAAAAAMQZ/aRRUsL/8AALKBAAAAEAGf+XRCvwAGmsq7q/HeNuAAAAAQAZ/7akK/AAaZK2L1dhz0QQAAABJBm+BJqEFsmUwIb//+p4QAAScAAAAMQZ4eRRUsL/8AALKAAAAAEAGePXRCvwAGmsq7q/HeNuAAAAAQAZ4/akK/AAaZK2L1dhz0QQAAABJBmiRJqEFsmUwIb//+p4QAAScAAAAMQZ5CRRUsL/8AALKBAAAAEAGeYXRCvwAGmsq7q/HeNuAAAAAQAZ5jakK/AAaZK2L1dhz0QQAAABxBmmhJqEFsmUwIX//+jLAAIADjpca9/3zp8S9BAAAAEEGehkUVLC//AAT6gQUocBkAAAAPAZ6ldEK/AAaayru83gJBAAAAEAGep2pCvwAGwdU8mB6+cIAAAAAaQZqpS6hCEFskRggoB/IB/YeAIV/+OEAAEXAAAAvYbW9vdgAAAGxtdmhkAAAAAAAAAAAAAAAAAAAD6AAAH5AAAQAAAQAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgAACwJ0cmFrAAAAXHRraGQAAAADAAAAAAAAAAAAAAABAAAAAAAAH5AAAAAAAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAABAAAAAARAAAAEQAAAAAAAkZWR0cwAAABxlbHN0AAAAAAAAAAEAAB+QAAAEAAABAAAAAAp6bWRpYQAAACBtZGhkAAAAAAAAAAAAAAAAAAAyAAABlABVxAAAAAAALWhkbHIAAAAAAAAAAHZpZGUAAAAAAAAAAAAAAABWaWRlb0hhbmRsZXIAAAAKJW1pbmYAAAAUdm1oZAAAAAEAAAAAAAAAAAAAACRkaW5mAAAAHGRyZWYAAAAAAAAAAQAAAAx1cmwgAAAAAQAACeVzdGJsAAAAlXN0c2QAAAAAAAAAAQAAAIVhdmMxAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAAAARABEABIAAAASAAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGP//AAAAL2F2Y0MB9AAN/+EAF2f0AA2RmygiEdCAAAADAIAAABkHihTLAQAFaOvjxEgAAAAYc3R0cwAAAAAAAAABAAAAygAAAgAAAAAUc3RzcwAAAAAAAAABAAAAAQAABbBjdHRzAAAAAAAAALQAAAAFAAAEAAAAAAEAAAYAAAAAAQAAAgAAAAACAAAEAAAAAAEAAAgAAAAAAgAAAgAAAAABAAAGAAAAAAEAAAIAAAAAAQAABgAAAAABAAACAAAAAAEAAAQAAAAAAQAABgAAAAABAAACAAAAAAEAAAYAAAAAAQAAAgAAAAACAAAEAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAABAAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAgAAAAAAgAAAgAAAAAFAAAEAAAAAAEAAAgAAAAAAgAAAgAAAAAFAAAEAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAACAAAEAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAQAAAAAAQAACAAAAAACAAACAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAMAAAQAAAAAAQAACAAAAAACAAACAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAQAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAABAAAAAAcc3RzYwAAAAAAAAABAAAAAQAAAMoAAAABAAADPHN0c3oAAAAAAAAAAAAAAMoAAAV4AAAAHAAAABsAAAAcAAAAHQAAACIAAAATAAAAHQAAAB0AAAAfAAAAFgAAABIAAAAhAAAAFAAAACEAAAATAAAAHQAAACIAAAAUAAAAIgAAABQAAAAcAAAAHQAAACEAAAAUAAAAFAAAABMAAAAeAAAAFQAAABcAAAAUAAAAEwAAAB0AAAAWAAAAEgAAAB8AAAAbAAAAHgAAABwAAAAdAAAAHwAAABUAAAASAAAAHQAAABwAAAAdAAAAHAAAAB0AAAAaAAAAEgAAABQAAAATAAAAIgAAABkAAAAUAAAAFAAAAB4AAAAdAAAAGgAAABIAAAAUAAAAEwAAABcAAAAQAAAAEwAAABMAAAAXAAAAEAAAABMAAAATAAAAIAAAABQAAAAUAAAAEwAAABcAAAAQAAAAEwAAABMAAAAXAAAAEAAAABMAAAATAAAAFwAAABAAAAATAAAAEwAAABcAAAAQAAAAEwAAABMAAAAXAAAAEAAAABMAAAATAAAAFwAAABAAAAATAAAAEwAAABcAAAAQAAAAEwAAABMAAAAXAAAAEAAAABMAAAATAAAAFwAAABAAAAATAAAAEwAAABcAAAAQAAAAEwAAABMAAAAXAAAAEAAAABMAAAATAAAAIAAAABQAAAATAAAAEwAAABYAAAAQAAAAFAAAABMAAAAWAAAAEAAAABQAAAATAAAAHQAAAB0AAAAWAAAAEgAAACAAAAATAAAAFQAAABAAAAATAAAAEwAAAB0AAAAdAAAAHQAAACIAAAAWAAAAEwAAABsAAAAUAAAAKQAAABYAAAATAAAAFAAAAB4AAAAhAAAAFAAAABQAAAAUAAAAFwAAABAAAAAUAAAAFAAAABcAAAAQAAAAFAAAABQAAAAXAAAAEAAAABQAAAAUAAAAFwAAABAAAAAUAAAAFAAAABcAAAAQAAAAFAAAABQAAAAXAAAAEAAAABQAAAAUAAAAFwAAABAAAAAUAAAAFAAAABcAAAAQAAAAFAAAABQAAAAWAAAAEAAAABQAAAAUAAAAFgAAABAAAAAUAAAAFAAAACAAAAAUAAAAEwAAABQAAAAeAAAAFHN0Y28AAAAAAAAAAQAAADAAAABidWR0YQAAAFptZXRhAAAAAAAAACFoZGxyAAAAAAAAAABtZGlyYXBwbAAAAAAAAAAAAAAAAC1pbHN0AAAAJal0b28AAAAdZGF0YQAAAAEAAAAATGF2ZjU3LjgzLjEwMA==\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(display_videos('fc_train20.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "__Question 8__ Implement the DQN training algorithm using a CNN (for example, 2 convolutional layers and one final fully connected layer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN_CNN(DQN):\n",
    "    def __init__(self, *args, lr=0.1, momentum=0.0, **kwargs):\n",
    "        super(DQN_CNN, self).__init__(*args,**kwargs)\n",
    "        \n",
    "        ###### FILL IN\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(64, kernel_size = 3, activation=\"relu\", input_shape = (5, 5, self.n_state)))\n",
    "        model.add(Conv2D(32, kernel_size = 3, activation = \"relu\"))\n",
    "        #model.add(MaxPooling2D((2,2)))\n",
    "        model.add(Reshape((32, )))\n",
    "        model.add(Dense(4))\n",
    "        \n",
    "        model.compile(SGD(lr=lr, decay=1e-4, momentum=momentum), \"mse\")\n",
    "        self.model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_38 (Conv2D)           (None, 3, 3, 64)          1216      \n",
      "_________________________________________________________________\n",
      "conv2d_39 (Conv2D)           (None, 1, 1, 32)          18464     \n",
      "_________________________________________________________________\n",
      "reshape_25 (Reshape)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 4)                 132       \n",
      "=================================================================\n",
      "Total params: 19,812\n",
      "Trainable params: 19,812\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-f0ac10e0355a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcnn_agent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDQN_CNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcnn_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mcnn_agent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnn_agent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnn_epochs_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cnn_train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-48-24317fb268aa>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(agent, env, epoch, prefix)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;31m# Apply the reinforcement strategy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreinforce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgame_over\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;31m# Save as a mp4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-49-1508bc812afd>\u001b[0m in \u001b[0;36mreinforce\u001b[0;34m(self, state, next_state, action, reward, game_over)\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m                 \u001b[0;31m######## FILL IN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m                 \u001b[0mtarget_q\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmemory_action\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmemory_reward\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscount\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_Q\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemory_next_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0;31m# HINT: Clip the target to avoid exploiding gradients.. -- clipping is a bit tighter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mtarget_q\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_q\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-49-1508bc812afd>\u001b[0m in \u001b[0;36mmax_Q\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmax_Q\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0marg_max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_Q\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax_Q\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmax_Q\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-49-1508bc812afd>\u001b[0m in \u001b[0;36margmax_Q\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0margmax_Q\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;31m#available_actions = self.available_actions(state)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0mQ_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQ\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# self.Q() will return a 1 x 4 array of arrays.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m         \u001b[0marg_max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQ_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mQ_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0marg_max\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-49-1508bc812afd>\u001b[0m in \u001b[0;36mQ\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mQ\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mname_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'model.h5'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mname_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'model.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1076\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1077\u001b[0m           \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1078\u001b[0;31m           callbacks=callbacks)\n\u001b[0m\u001b[1;32m   1079\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3292\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cnn_epochs_train = 101\n",
    "cnn_lr = 0.3\n",
    "\n",
    "env = Environment(grid_size=size, max_time=T, temperature=0.3)\n",
    "cnn_agent = DQN_CNN(size, lr=cnn_lr, momentum=0.9, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
    "cnn_agent.model.summary()\n",
    "train(cnn_agent, env, cnn_epochs_train, prefix='cnn_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" controls>\n",
       "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(display_videos('cnn_train20.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "__Question 9__ Test both algorithms and compare their performances. Which issue(s) do you observe? Observe also different behaviors by changing the temperature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test of the CNN\n",
      "Win/lose count 19.5/3.0. Average score (16.5)\n",
      "Win/lose count 19.0/4.0. Average score (15.75)\n",
      "Win/lose count 16.0/0. Average score (15.833333333333334)\n",
      "Win/lose count 17.5/3.0. Average score (15.5)\n",
      "Win/lose count 13.5/3.0. Average score (14.5)\n",
      "Win/lose count 22.5/3.0. Average score (15.333333333333334)\n",
      "Win/lose count 15.0/3.0. Average score (14.857142857142858)\n",
      "Win/lose count 18.5/4.0. Average score (14.8125)\n",
      "Win/lose count 8.0/1.0. Average score (13.944444444444445)\n",
      "Win/lose count 9.5/3.0. Average score (13.2)\n",
      "Win/lose count 13.0/5.0. Average score (12.727272727272727)\n",
      "Win/lose count 17.5/6.0. Average score (12.625)\n",
      "Win/lose count 22.5/4.0. Average score (13.076923076923077)\n",
      "Win/lose count 22.0/6.0. Average score (13.285714285714286)\n",
      "Win/lose count 16.0/2.0. Average score (13.333333333333334)\n",
      "Win/lose count 12.0/4.0. Average score (13.0)\n",
      "Win/lose count 21.5/5.0. Average score (13.205882352941176)\n",
      "Win/lose count 7.0/2.0. Average score (12.75)\n",
      "Win/lose count 18.5/2.0. Average score (12.947368421052632)\n",
      "Win/lose count 24.5/1.0. Average score (13.475)\n",
      "Win/lose count 18.5/1.0. Average score (13.666666666666666)\n",
      "Final score: 13.666666666666666\n",
      "Test of the FC\n",
      "Win/lose count 9.5/0. Average score (9.5)\n",
      "Win/lose count 5.0/1.0. Average score (6.75)\n",
      "Win/lose count 3.0/1.0. Average score (5.166666666666667)\n",
      "Win/lose count 7.5/1.0. Average score (5.5)\n",
      "Win/lose count 5.5/1.0. Average score (5.3)\n",
      "Win/lose count 13.0/1.0. Average score (6.416666666666667)\n",
      "Win/lose count 17.0/2.0. Average score (7.642857142857143)\n",
      "Win/lose count 9.0/3.0. Average score (7.4375)\n",
      "Win/lose count 7.0/3.0. Average score (7.055555555555555)\n",
      "Win/lose count 13.5/5.0. Average score (7.2)\n",
      "Win/lose count 16.0/3.0. Average score (7.7272727272727275)\n",
      "Win/lose count 8.5/3.0. Average score (7.541666666666667)\n",
      "Win/lose count 9.5/4.0. Average score (7.384615384615385)\n",
      "Win/lose count 5.5/1.0. Average score (7.178571428571429)\n",
      "Win/lose count 16.5/6.0. Average score (7.4)\n",
      "Win/lose count 7.0/3.0. Average score (7.1875)\n",
      "Win/lose count 11.5/1.0. Average score (7.382352941176471)\n",
      "Win/lose count 10.0/4.0. Average score (7.305555555555555)\n",
      "Win/lose count 11.5/1.0. Average score (7.473684210526316)\n",
      "Win/lose count 19.0/2.0. Average score (7.95)\n",
      "Win/lose count 5.5/0. Average score (7.833333333333333)\n",
      "Final score: 7.833333333333333\n"
     ]
    }
   ],
   "source": [
    "env = Environment(grid_size=size, max_time=T,temperature=0.3)\n",
    "agent_cnn = DQN_CNN(size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
    "agent_cnn.load(name_weights='cnn_trainmodel.h5',name_model='cnn_trainmodel.json')\n",
    "\n",
    "agent_fc = DQN_FC(size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
    "agent_fc.load(name_weights='fc_trainmodel.h5',name_model='fc_trainmodel.json')\n",
    "\n",
    "epochs_test = 21\n",
    "print('Test of the CNN') # 12.238095238095237\n",
    "test(agent_cnn,env,epochs_test,prefix='cnn_test')\n",
    "print('Test of the FC') #9.738095238095237\n",
    "test(agent_fc,env,epochs_test,prefix='fc_test') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" controls>\n",
       "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(display_videos('cnn_test10.mp4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" controls>\n",
       "                <source src=\"data:video/mp4;base64,AAAAIGZ0eXBpc29tAAACAGlzb21pc28yYXZjMW1wNDEAAAAIZnJlZQAAGMZtZGF0AAACrQYF//+p3EXpvebZSLeWLNgg2SPu73gyNjQgLSBjb3JlIDE1MiByMjg1NCBlOWE1OTAzIC0gSC4yNjQvTVBFRy00IEFWQyBjb2RlYyAtIENvcHlsZWZ0IDIwMDMtMjAxNyAtIGh0dHA6Ly93d3cudmlkZW9sYW4ub3JnL3gyNjQuaHRtbCAtIG9wdGlvbnM6IGNhYmFjPTEgcmVmPTMgZGVibG9jaz0xOjA6MCBhbmFseXNlPTB4MToweDExMSBtZT1oZXggc3VibWU9NyBwc3k9MSBwc3lfcmQ9MS4wMDowLjAwIG1peGVkX3JlZj0xIG1lX3JhbmdlPTE2IGNocm9tYV9tZT0xIHRyZWxsaXM9MSA4eDhkY3Q9MCBjcW09MCBkZWFkem9uZT0yMSwxMSBmYXN0X3Bza2lwPTEgY2hyb21hX3FwX29mZnNldD00IHRocmVhZHM9OCBsb29rYWhlYWRfdGhyZWFkcz0xIHNsaWNlZF90aHJlYWRzPTAgbnI9MCBkZWNpbWF0ZT0xIGludGVybGFjZWQ9MCBibHVyYXlfY29tcGF0PTAgY29uc3RyYWluZWRfaW50cmE9MCBiZnJhbWVzPTMgYl9weXJhbWlkPTIgYl9hZGFwdD0xIGJfYmlhcz0wIGRpcmVjdD0xIHdlaWdodGI9MSBvcGVuX2dvcD0wIHdlaWdodHA9MiBrZXlpbnQ9MjUwIGtleWludF9taW49MjUgc2NlbmVjdXQ9NDAgaW50cmFfcmVmcmVzaD0wIHJjX2xvb2thaGVhZD00MCByYz1jcmYgbWJ0cmVlPTEgY3JmPTIzLjAgcWNvbXA9MC42MCBxcG1pbj0wIHFwbWF4PTY5IHFwc3RlcD00IGlwX3JhdGlvPTEuNDAgYXE9MToxLjAwAIAAAAMcZYiEADP//vaG+BTYUyP+T7/8I/+5H7cfWfrixkIJvrVeQ9GAMl8a/5lGYaXpyc8t7R+vTNAEZz6HlLJIofgUkwDfMsjnE+I5enspOLscylLon41XqQ7G674zPsDDMt4N3LipEvs+gbt3wPWOUZsVgjU0lbPrACg69PP5JxUivnonDkwKcg/BFZtHmrtTTHijivLHS+hdIsQpowKx35mvzJf/TCsaTf/dSY7SuocihLI+yBjYCvZXAo24tK0jcwuqeYUvsw3y+HSMNtp0ds8/Ffj/6NBZ/eTO07MvJu/HwlV9ptMKMj12X/hDVWV7tW0jFySJoMu2IumnSTz0bpCwRoGvoQZ5bTvWiB1+45TVrYksdNVmfe3E9ecJhuYnXwQUC6BJnY+7jDsxhR2Nel8Ufen9FJVK4zOUCk1fNSv2D7jPkEwYxiyRFNpzfNI0Du0p2mHiFcXcF9JyUujFHicZl6WLchon4YdAGLOEH9KPdO33k+skchbMIbCsddiXmdWCcznY8mchr6zZamsVBF0t//Z/45+AAAEV0N22GaiPDJWb9wd7DcLUDCSQOKF76belkbAU1Td8LIuS5B6jkcd1z3eIFWtA4aVN0lotSPnKf1k5aHGZwh0B68P957lJGxrKR+PonglFeHzIuvU4HiTdUEFL4ZUGQh6bgprNJe+exVYtPcth+adCfaWgCSvzBLmqMvBbr/6Gy9/bCP1JoSEHSbvNhhzP0E0glLRGfQ8/GdmhldJor1dKZbH6OTdtiNqNTMpSPTY1l96TDpIuG6wQRXxORMj0s4meBveFd8U3Suk5lnyAkSQ84f/8PVKg7x3zDPY30J16cFYthcBwOHu1yKwBUk/1ZARAeHQlgHAB6UpdbMAOnHIaahNppWtWU9FFI9EpKO3KALKC00n10Mjs1WImgqj3eC+RG7I3r4poc7kGR2PyyIUK8hfd2QpYZ2WQiQGqlIWcsKxEadFSLtIw+q4Sh/px9yaKeGsyVHK/kxB2nr9E9xkk/4hAeFPaRY+WIvqkFgs/tjJ+qtHDOZWI4OYgNPizgehygoABHQAAABNBmiFsQ3/+p4QAfsmCnWdPutu9AAAAG0GaQzwhkymEM//+nhADHr7muOfSC/kgl/j1bQAAABABnmJqQr8AqFhHkwPXtvSAAAAAGkGaZEnhDyZTAhn//p4QBNDhHP4dlso/CFlBAAAAGkGahUnhDyZTAhv//qeEAoihjU8oK1P8Wp2BAAAAGkGapknhDyZTAhv//qeEDPcT/TWOvU/uMPmBAAAAHUGayEnhDyZTBRE8N//+p4QM9xP9HmN17ISItyHzAAAADwGe52pCvwKuTKZtmOwjZgAAAB1BmupJ4Q8mUwU8N//+p4QKTsx9aW5GP8KNbmf0vAAAABABnwlqQr8CdWX6o+JFzndBAAAAGUGbC0nhDyZTAh3//qmWARfx5+6KQpgxK2AAAAAbQZsuSeEPJlMCG//+p4QBLfjp7vN1+sUI/PiwAAAAEkGfTEURPCv/APKrg1x73qDmgQAAAA4Bn21qQr8A8oMx6IrapwAAABxBm3FJqEFomUwIb//+p4QAwrq0ghE/y2Slx62hAAAAEkGfj0URLCv/AJ9YV7CwX5a0gAAAAA4Bn7BqQr8An1iY84IFpAAAABJBm7VJqEFsmUwIb//+p4QAAScAAAAMQZ/TRRUsL/8AALKAAAAADwGf8nRCvwCj2jujtvhVHwAAAA8Bn/RqQr8AnVlG6z1Z6fMAAAAaQZv2SahBbJlMCG///qeEAMe6tIIRP8ts9YAAAAAdQZoYSeEKUmUwUVLDv/6plgCgwWYtM0BVfHn0JoMAAAAPAZ43akK/AP7Z5bhs2pkzAAAAGEGaPEnhDomUwIb//qeEAT346fbyVC9zegAAABVBnlpFFTwv/wEex4+ixXbzXx5BpU0AAAAQAZ55dEK/AZOyruQ2VKPh4AAAABABnntqQr8BiSW068AT+TiBAAAAGkGafkmoQWiZTBTw7/6plgCg45Bz3tL7nN6BAAAADwGenWpCvwD+2eW4bNqZMwAAABhBmoJJ4QpSZTAhv/6nhAE9+On28lQvc3oAAAASQZ6gRTRML/8BHuM/LdYVW3SdAAAAEAGe33RCvwGTsq7kNlSj4eAAAAAQAZ7BakK/AYkltOvAE/k4gQAAABpBmsRJqEFomUwU8O/+qZYAoOOQc97S+5zegAAAAA8BnuNqQr8A/tnluGzamTMAAAAYQZroSeEKUmUwIb/+p4QBPfjp9vJUL3N7AAAAEkGfBkU0TC//AR7jPy3WFVt0nQAAABABnyV0Qr8Bk7Ku5DZUo+HhAAAAEAGfJ2pCvwGJJbTrwBP5OIAAAAAaQZsqSahBaJlMFPDv/qmWAKDjkHPe0vuc3oAAAAAPAZ9JakK/AP7Z5bhs2pkzAAAAGEGbTknhClJlMCG//qeEAT346fbyVC9zegAAABJBn2xFNEwv/wEe4z8t1hVbdJwAAAAQAZ+LdEK/AZOyruQ2VKPh4QAAABABn41qQr8BiSW068AT+TiBAAAAGkGbkEmoQWiZTBTw7/6plgCg45Bz3tL7nN6BAAAADwGfr2pCvwD+2eW4bNqZMwAAABhBm7RJ4QpSZTAhv/6nhAE9+On28lQvc3oAAAASQZ/SRTRML/8BHuM/LdYVW3SdAAAAEAGf8XRCvwGTsq7kNlSj4eAAAAAQAZ/zakK/AYkltOvAE/k4gAAAABpBm/ZJqEFomUwU8O/+qZYAoOOQc97S+5zegQAAAA8BnhVqQr8A/tnluGzamTMAAAAYQZoaSeEKUmUwId/+qZYAoftL+ucSbjm9AAAAEkGeOEU0TC//AR7jPy3WFVt0nQAAABABnld0Qr8Bk7Ku5DZUo+HgAAAAEAGeWWpCvwGJJbTrwBP5OIEAAAASQZpeSahBaJlMCG///qeEAAEnAAAAEUGefEURLC//AL7a4zfu2/yBAAAADwGem3RCvwD+9J3Bsl4yZwAAABABnp1qQr8A/pPnOtDC8QeAAAAAGkGagEmoQWyZTBRMO//+qZYAoNzo572l9zm9AAAADwGev2pCvwD+2eW4bNqZMwAAABhBmqRJ4QpSZTAhv/6nhAE9+On28lQvc3oAAAAVQZ7CRTRML/8BHsePosV2818eQaVNAAAAEAGe4XRCvwGTsq7kNlSj4eAAAAAQAZ7jakK/AYkltOvAE/k4gQAAABpBmuZJqEFomUwU8O/+qZYAoOOQc97S+5zegQAAAA8BnwVqQr8A/tnluGzamTMAAAAYQZsKSeEKUmUwIb/+p4QBPfjp9vJUL3N7AAAAEkGfKEU0TC//AR7jPy3WFVt0nAAAABABn0d0Qr8Bk7Ku5DZUo+HgAAAAEAGfSWpCvwGJJbTrwBP5OIEAAAAaQZtMSahBaJlMFPDv/qmWAKDjkHPe0vuc3oAAAAAPAZ9rakK/AP7Z5bhs2pkzAAAAGEGbcEnhClJlMCG//qeEAT346fbyVC9zewAAABJBn45FNEwv/wEe4z8t1hVbdJ0AAAAQAZ+tdEK/AZOyruQ2VKPh4QAAABABn69qQr8BiSW068AT+TiAAAAAGkGbskmoQWiZTBTw7/6plgCg45Bz3tL7nN6AAAAADwGf0WpCvwD+2eW4bNqZMwAAABpBm9ZJ4QpSZTAhv/6nhAJiQyt/eGAmv82B+QAAABBBn/RFNEwv/wEeoDl5E+bgAAAAEAGeE3RCvwGTsq7kNlSj4eEAAAAPAZ4VakK/AYmxYF1/fsHAAAAAGkGaGUmoQWiZTAhv//6nhAJp3U/QgC3QKqSBAAAAEUGeN0URLCv/AZNm5rj3vUEbAAAADgGeWGpCvwGTJDPRFbM+AAAAHUGaW0moQWyZTBRMN//+p4QBNfjp9zIwtmKEcucdAAAADwGeempCvwD4A/qkUCVRqQAAABhBmn5J4QpSZTAhn/6eEAMKvuNC6b7rbH0AAAARQZ6cRTRMK/8Ao9hWCQlb7cEAAAAOAZ69akK/AKPYmK4ElwQAAAAZQZq/SahBaJlMCGf//p4QAx6+40LpvutsXAAAABhBmsBJ4QpSZTAhn/6eEAMj6+/kSI+sIh8AAAAYQZrhSeEOiZTAhn/+nhAB/fX38iRH1hGpAAAAHkGbA0nhDyZTBRE8M//+nhABUfdN7gB1bndcR9UTbQAAABABnyJqQr8ARWT5zrQwvJzAAAAAGEGbJEnhDyZTAhn//p4QANP6+7tObuLeHQAAABhBm0VJ4Q8mUwIZ//6eEADO+vv5EiPrCg8AAAAYQZtmSeEPJlMCGf/+nhAAg3xD+2Qx9YWfAAAAGEGbh0nhDyZTAhn//p4QAFa902MuTZVyJQAAABlBm6hJ4Q8mUwIb//6nhAAVr3U/UcaEh03AAAAAGUGbyUnhDyZTAhv//qeEAA4gPCnWdPuumYAAAAAfQZvtSeEPJlMCG//+p4QADo+wfzaXei4a+tUyEjHPeQAAABZBngtFETwv/wAI7HzpnFGbysmuhL6AAAAADwGeKnRCvwAMRIfjeoI3RwAAAA8BnixqQr8ADEEtKkUCVx8AAAAZQZowSahBaJlMCGf//p4QACTfEP7ZDH1idwAAABJBnk5FESwr/wAHxVwa49714IEAAAAPAZ5vakK/AAfEH9UigSwnAAAAGUGacUmoQWyZTAhn//6eEAAX/193ac3cX9wAAAAYQZqSSeEKUmUwIZ/+nhAAI6cI5/DnN9hjAAAAGEGas0nhDomUwIZ//p4QADcyGOfw5zfXpQAAABhBmtRJ4Q8mUwIb//6nhAAON7B69mfBFu8AAAAdQZr2SeEPJlMFETwz//6eEAA2Pr79UHzVOG5QPaEAAAAPAZ8VakK/AAtbWUzbMjdpAAAAGUGbF0nhDyZTAhv//qeEABRvRP9VvmPxUkEAAAAcQZs5SeEPJlMFETwz//6eEABPfabfd0QKNb/sYQAAAA8Bn1hqQr8AEFkymbZkbaYAAAAYQZtaSeEPJlMCGf/+nhAAS74h/bIY+sNtAAAAGEGbe0nhDyZTAhv//qeEAAyfsHr2Z8EXGwAAABhBm5xJ4Q8mUwIb//6nhAAMT7B69mfBFyUAAAAeQZu+SeEPJlMFETw3//6nhAAL/7B/Pg+hdrZihH+nAAAAEAGf3WpCvwAJrJ851oYX9cAAAAAoQZvBSeEPJlMCGf/+nhAAHR9ff1b2qxfApsn2f4FM1xB8CiT2/x5Z2gAAABJBn/9FETwr/wAGIJlphaJf7tkAAAAPAZ4AakK/AAQXYjyXM+WjAAAAGkGaAkmoQWiZTAhv//6nhAAHwOM/1I6OReJhAAAAGUGaI0nhClJlMCG//qeEAAfsHhTrOn3XroAAAAAYQZpGSeEOiZTAhv/+p4QACCj5jyMT/Lg5AAAAD0GeZEURPCv/AAbAjQOjwQAAABABnoVqQr8ABq9RPIjr+HHBAAAAGEGah0moQWiZTAhv//6nhAAIN9HNUMwXvwAAAB1BmqlJ4QpSZTBREsO//qmWAAQH48/l2e1CyFLpZwAAABABnshqQr8ABpiO3OtDDBZAAAAAHkGazUnhDomUwIb//qeEAAxKxvVNbDFav+xsGP+AhQAAABBBnutFFTwv/wAHQTo9FEJYAAAADwGfCnRCvwAEFtGLgPz7wAAAABABnwxqQr8ACfWPHK/txEbBAAAAGkGbEEmoQWiZTAhv//6nhAAMT7B/hOC3QrRBAAAAEUGfLkURLCv/AAo9KN5pvetfAAAADwGfT2pCvwAKO23SjSHkIQAAABpBm1FJqEFsmUwIb//+p4QAB8vYP8JwW6F6wAAAABxBm3VJ4QpSZTAhv/6nhAAMPdSs24FvkcBzfa0RAAAAEEGfk0U0TC//AAdBOj0UQlgAAAAPAZ+ydEK/AAQW0YuA/PvAAAAAEAGftGpCvwAJ9Y8cr+3ERsEAAAAaQZu2SahBaJlMCG///qeEAAxPsH+E4LdCtEAAAAAYQZvXSeEKUmUwId/+qZYAA+vtL+efpupBAAAAGkGb+0nhDomUwIb//qeEAAw+Bl0C94YHN9rRAAAAEEGeGUURPC//AAdBOj0UQlgAAAAPAZ44dEK/AAQW0YuA/PvBAAAAEAGeOmpCvwAJ9Y8cr+3ERsAAAAAaQZo+SahBaJlMCG///qeEAAxPsH+E4LdCtEEAAAARQZ5cRREsK/8ACj0o3mm9618AAAAPAZ59akK/AAo7bdKNIeQhAAAAGkGaf0moQWyZTAhv//6nhAAHy9g/wnBboXrAAAAAHEGag0nhClJlMCG//qeEAAw91KzbgW+RwHN9rREAAAAQQZ6hRTRML/8AB0E6PRRCWAAAAA8BnsB0Qr8ABBbRi4D8+8EAAAAQAZ7CakK/AAn1jxyv7cRGwAAAABlBmsZJqEFomUwIZ//+nhAAL/6+/kSI+sQ/AAAAEUGe5EURLCv/AAo9KN5pvetfAAAADwGfBWpCvwAKO23SjSHkIQAAABlBmwdJqEFsmUwIb//+p4QAB8vYPXsz4IvvAAAAHUGbKUnhClJlMFFSwz/+nhAALVXuuI5/SOvv6bAgAAAAEAGfSGpCvwAJbtEJuM+vV9gAAAAYQZtKSeEOiZTAhn/+nhAARU4Rz+HOb66vAAAAG0Gba0nhDyZTAhn//p4QAGvkMc/hz4gcP8L5gAAAABhBm4xJ4Q8mUwIb//6nhAArHon+pSAVfcAAAAAdQZuuSeEPJlMFETw3//6nhAArXup98M9DKGrLon0AAAAQAZ/NakK/ACKyfOdaGF6MwQAAABlBm89J4Q8mUwIb//6nhAAbH2D/CcFuhOpBAAAAGUGb8EnhDyZTAh3//qmWAAjPx5+/ZBuKnuAAAAAWQZoUSeEPJlMCHf/+qZYAA6nwo+6pYAAAAA5BnjJFETwv/wAEVoA44QAAABABnlF0Qr8ACRKkd+AD7j3AAAAAEAGeU2pCvwAOKahz/Mt4WcAAAAATQZpYSahBaJlMCHf//qmWAACVgQAAAAxBnnZFESwv/wAAsoAAAAAQAZ6VdEK/AAkSpHfgA+49wQAAABABnpdqQr8ADimoc/zLeFnBAAAAE0GanEmoQWyZTAh3//6plgAAlYAAAAAMQZ66RRUsL/8AALKBAAAAEAGe2XRCvwAJEqR34APuPcAAAAAQAZ7bakK/AA4pqHP8y3hZwQAAABJBmsBJqEFsmUwIb//+p4QAAScAAAAMQZ7+RRUsL/8AALKAAAAAEAGfHXRCvwAJEqR34APuPcAAAAAQAZ8fakK/AA4pqHP8y3hZwQAAABJBmwRJqEFsmUwIb//+p4QAAScAAAAMQZ8iRRUsL/8AALKBAAAAEAGfQXRCvwAJEqR34APuPcAAAAAQAZ9DakK/AA4pqHP8y3hZwQAAABJBm0hJqEFsmUwIX//+jLAABI0AAAAMQZ9mRRUsL/8AALKBAAAAEAGfhXRCvwAJEqR34APuPcEAAAAQAZ+HakK/AA4pqHP8y3hZwAAAABpBm4lLqEIQWyRGCCgH8gH9h4AhX/44QAARcAAAC5htb292AAAAbG12aGQAAAAAAAAAAAAAAAAAAAPoAAAfkAABAAABAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAAAKwnRyYWsAAABcdGtoZAAAAAMAAAAAAAAAAAAAAAEAAAAAAAAfkAAAAAAAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAEAAAAABEAAAARAAAAAAACRlZHRzAAAAHGVsc3QAAAAAAAAAAQAAH5AAAAQAAAEAAAAACjptZGlhAAAAIG1kaGQAAAAAAAAAAAAAAAAAADIAAAGUAFXEAAAAAAAtaGRscgAAAAAAAAAAdmlkZQAAAAAAAAAAAAAAAFZpZGVvSGFuZGxlcgAAAAnlbWluZgAAABR2bWhkAAAAAQAAAAAAAAAAAAAAJGRpbmYAAAAcZHJlZgAAAAAAAAABAAAADHVybCAAAAABAAAJpXN0YmwAAACVc3RzZAAAAAAAAAABAAAAhWF2YzEAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAABEAEQAEgAAABIAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY//8AAAAvYXZjQwH0AA3/4QAXZ/QADZGbKCIR0IAAAAMAgAAAGQeKFMsBAAVo6+PESAAAABhzdHRzAAAAAAAAAAEAAADKAAACAAAAABRzdHNzAAAAAAAAAAEAAAABAAAFcGN0dHMAAAAAAAAArAAAAAIAAAQAAAAAAQAABgAAAAABAAACAAAAAAMAAAQAAAAAAQAABgAAAAABAAACAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAEAAAAAAEAAAgAAAAAAgAAAgAAAAABAAAIAAAAAAIAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAEAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAABgAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAABgAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAABgAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAABgAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACAAAAAACAAACAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAIAAAAAAIAAAIAAAAAAwAABAAAAAABAAAGAAAAAAEAAAIAAAAABgAABAAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAgAAAAAAgAAAgAAAAAEAAAEAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAEAAAAAAEAAAYAAAAAAQAAAgAAAAADAAAEAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAIAAAAAAIAAAIAAAAAAgAABAAAAAABAAAIAAAAAAIAAAIAAAAAAQAABAAAAAABAAAGAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAIAAAAAAIAAAIAAAAAAQAABAAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAIAAAQAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAIAAAAAAIAAAIAAAAAAQAABAAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAgAAAAAAgAAAgAAAAABAAAEAAAAAAEAAAYAAAAAAQAAAgAAAAADAAAEAAAAAAEAAAYAAAAAAQAAAgAAAAACAAAEAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAQAAAAAHHN0c2MAAAAAAAAAAQAAAAEAAADKAAAAAQAAAzxzdHN6AAAAAAAAAAAAAADKAAAF0QAAABcAAAAfAAAAFAAAAB4AAAAeAAAAHgAAACEAAAATAAAAIQAAABQAAAAdAAAAHwAAABYAAAASAAAAIAAAABYAAAASAAAAFgAAABAAAAATAAAAEwAAAB4AAAAhAAAAEwAAABwAAAAZAAAAFAAAABQAAAAeAAAAEwAAABwAAAAWAAAAFAAAABQAAAAeAAAAEwAAABwAAAAWAAAAFAAAABQAAAAeAAAAEwAAABwAAAAWAAAAFAAAABQAAAAeAAAAEwAAABwAAAAWAAAAFAAAABQAAAAeAAAAEwAAABwAAAAWAAAAFAAAABQAAAAWAAAAFQAAABMAAAAUAAAAHgAAABMAAAAcAAAAGQAAABQAAAAUAAAAHgAAABMAAAAcAAAAFgAAABQAAAAUAAAAHgAAABMAAAAcAAAAFgAAABQAAAAUAAAAHgAAABMAAAAeAAAAFAAAABQAAAATAAAAHgAAABUAAAASAAAAIQAAABMAAAAcAAAAFQAAABIAAAAdAAAAHAAAABwAAAAiAAAAFAAAABwAAAAcAAAAHAAAABwAAAAdAAAAHQAAACMAAAAaAAAAEwAAABMAAAAdAAAAFgAAABMAAAAdAAAAHAAAABwAAAAcAAAAIQAAABMAAAAdAAAAIAAAABMAAAAcAAAAHAAAABwAAAAiAAAAFAAAACwAAAAWAAAAEwAAAB4AAAAdAAAAHAAAABMAAAAUAAAAHAAAACEAAAAUAAAAIgAAABQAAAATAAAAFAAAAB4AAAAVAAAAEwAAAB4AAAAgAAAAFAAAABMAAAAUAAAAHgAAABwAAAAeAAAAFAAAABMAAAAUAAAAHgAAABUAAAATAAAAHgAAACAAAAAUAAAAEwAAABQAAAAdAAAAFQAAABMAAAAdAAAAIQAAABQAAAAcAAAAHwAAABwAAAAhAAAAFAAAAB0AAAAdAAAAGgAAABIAAAAUAAAAFAAAABcAAAAQAAAAFAAAABQAAAAXAAAAEAAAABQAAAAUAAAAFgAAABAAAAAUAAAAFAAAABYAAAAQAAAAFAAAABQAAAAWAAAAEAAAABQAAAAUAAAAHgAAABRzdGNvAAAAAAAAAAEAAAAwAAAAYnVkdGEAAABabWV0YQAAAAAAAAAhaGRscgAAAAAAAAAAbWRpcmFwcGwAAAAAAAAAAAAAAAAtaWxzdAAAACWpdG9vAAAAHWRhdGEAAAABAAAAAExhdmY1Ny44My4xMDA=\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(display_videos('fc_test20.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "The algorithm tends to not explore the map which can be an issue. We propose two ideas in order to encourage exploration:\n",
    "1. Incorporating a decreasing $\\epsilon$-greedy exploration. You can use the method ```set_epsilon```\n",
    "2. Append via the environment a new state that describes if a cell has been visited or not\n",
    "\n",
    "***\n",
    "__Question 10__ Design a new ```train_explore``` function and environment class ```EnvironmentExploring``` to tackle the issue of exploration.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_explore(agent,env,epoch,prefix=''):\n",
    "    # Number of won games\n",
    "    score = 0\n",
    "    loss = 0\n",
    "    list_win_scores = []\n",
    "    list_lose_scores = []\n",
    "    list_total_scores = []\n",
    "    list_losses = []\n",
    "    def set_epsilon_strategy(agent, state):\n",
    "        total_nbr_of_cells = state.shape[0] * state.shape[1]\n",
    "        malus_positions_cells = state[:, :, 2]\n",
    "        \n",
    "        nbr_of_malus_position = len(malus_positions_cells[malus_positions_cells > 0])\n",
    "        \n",
    "        ratio = nbr_of_malus_position / total_nbr_of_cells\n",
    "        \n",
    "        if ratio >= 0.75:\n",
    "            agent.set_epsilon(0.7)\n",
    "        elif ratio >= 0.5:\n",
    "            agent.set_epsilon(0.5)\n",
    "        elif ratio >= 0.25:\n",
    "            agent.set_epsilon(0.3)\n",
    "        else:\n",
    "            agent.set_epsilon(0.1)\n",
    "\n",
    "    \n",
    "    for e in range(epoch):\n",
    "        # At each epoch, we restart to a fresh game and get the initial state\n",
    "        state = env.reset()\n",
    "        # This assumes that the games will terminate\n",
    "        game_over = False\n",
    "\n",
    "        win = 0\n",
    "        lose = 0\n",
    "\n",
    "        while not game_over:\n",
    "            # The agent performs an action\n",
    "            action = agent.act(state)\n",
    "\n",
    "            # Apply an action to the environment, get the next state, the reward\n",
    "            # and if the games end\n",
    "            prev_state = state\n",
    "            state, reward, game_over, reward_without_malus_position = env.act(action, train = True)\n",
    "            set_epsilon_strategy(agent, state)\n",
    "\n",
    "            # Update the counters\n",
    "            if reward_without_malus_position > 0:\n",
    "                win = win + reward_without_malus_position\n",
    "            if reward_without_malus_position < 0:\n",
    "                lose = lose -reward_without_malus_position\n",
    "\n",
    "            # Apply the reinforcement strategy\n",
    "            loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
    "\n",
    "        # Save as a mp4\n",
    "        if e % 10 == 0:\n",
    "            env.draw(prefix+str(e))\n",
    "\n",
    "        # Update stats\n",
    "        score += win-lose\n",
    "\n",
    "        print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
    "                .format(e, epoch, loss, win, lose, win-lose))\n",
    "        list_win_scores.append(win)\n",
    "        list_lose_scores.append(lose)\n",
    "        list_total_scores.append(score)\n",
    "        list_losses.append(loss)\n",
    "        agent.save(name_weights=prefix+'model.h5',name_model=prefix+'model.json')\n",
    "        \n",
    "    return {\"loss\": list_losses, \"score\": list_total_scores, \"win\": list_win_scores, \"lose\": list_lose_scores}\n",
    "#     pass\n",
    "        \n",
    "class EnvironmentExploring(Environment):\n",
    "    def __init__(self, grid_size=10, max_time=500, temperature=0.1):\n",
    "        grid_size = grid_size+4\n",
    "        self.grid_size = grid_size\n",
    "        self.max_time = max_time\n",
    "        self.temperature = temperature\n",
    "\n",
    "        #board on which one plays\n",
    "        self.board = np.zeros((grid_size,grid_size))\n",
    "        self.position = np.zeros((grid_size,grid_size))\n",
    "        self.malus_position = np.zeros((grid_size,grid_size))\n",
    "        \n",
    "        # coordinate of the cat\n",
    "        self.x = 0\n",
    "        self.y = 1\n",
    "\n",
    "        # self time\n",
    "        self.t = 0\n",
    "\n",
    "        self.scale=16\n",
    "\n",
    "        self.to_draw = np.zeros((max_time+2, grid_size*self.scale, grid_size*self.scale, 3))\n",
    "\n",
    "    def act(self, action, train = False):\n",
    "        \"\"\"This function returns the new state, reward and decides if the\n",
    "        game ends.\"\"\"\n",
    "\n",
    "        self.get_frame(int(self.t))\n",
    "\n",
    "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
    "\n",
    "        self.position[0:2,:]= -1\n",
    "        self.position[:,0:2] = -1\n",
    "        self.position[-2:, :] = -1\n",
    "        self.position[:, -2:] = -1\n",
    "        #self.position[-2:, :] = -1\n",
    "\n",
    "        self.position[self.x, self.y] = 1\n",
    "        if action == 0:\n",
    "            if self.x == self.grid_size-3:\n",
    "                self.x = self.x-1\n",
    "            else:\n",
    "                self.x = self.x + 1\n",
    "        elif action == 1:\n",
    "            if self.x == 2:\n",
    "                self.x = self.x+1\n",
    "            else:\n",
    "                self.x = self.x-1\n",
    "        elif action == 2:\n",
    "            if self.y == self.grid_size - 3:\n",
    "                self.y = self.y - 1\n",
    "            else:\n",
    "                self.y = self.y + 1\n",
    "        elif action == 3:\n",
    "            if self.y == 2:\n",
    "                self.y = self.y + 1\n",
    "            else:\n",
    "                self.y = self.y - 1\n",
    "        else:\n",
    "            RuntimeError('Error: action not recognized')\n",
    "\n",
    "        self.t = self.t + 1\n",
    "#         reward = self.board[self.x, self.y]\n",
    "        reward = 0\n",
    "        reward_without_malus_position = 0\n",
    "        \n",
    "        if train:\n",
    "            reward = -self.malus_position[self.x, self.y]\n",
    "        self.malus_position[self.x, self.y] = 0.1\n",
    "        \n",
    "        reward = reward + self.board[self.x, self.y]\n",
    "        reward_without_malus_position = self.board[self.x, self.y]\n",
    "\n",
    "        self.board[self.x, self.y] = 0\n",
    "        game_over = self.t > self.max_time\n",
    "\n",
    "        # 3 \"feature\" states instead of 2\n",
    "        state = np.concatenate((self.malus_position.reshape(self.grid_size, self.grid_size,1),\n",
    "                                        self.board.reshape(self.grid_size, self.grid_size,1),\n",
    "                                self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
    "            \n",
    "        state = state[self.x-2:self.x+3,self.y-2:self.y+3,:]\n",
    "\n",
    "        return state, reward, game_over, reward_without_malus_position\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"This function resets the game and returns the initial state\"\"\"\n",
    "        \n",
    "        # random between min=3 and max= grid_size - 3\n",
    "        self.x = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
    "        self.y = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
    "\n",
    "        # Binom(1, temperature), size fois\n",
    "        bonus = 0.5 * np.random.binomial(1, self.temperature, size=self.grid_size**2)\n",
    "        bonus = bonus.reshape(self.grid_size,self.grid_size)\n",
    "\n",
    "        malus = -1.0 * np.random.binomial(1, self.temperature, size=self.grid_size**2)\n",
    "        malus = malus.reshape(self.grid_size, self.grid_size)\n",
    "\n",
    "        self.to_draw = np.zeros((self.max_time+2, self.grid_size*self.scale, self.grid_size*self.scale, 3))\n",
    "\n",
    "        # Pour ne pas avoir les malus aux mÃªmes positions que les bonus\n",
    "        malus[bonus>0]=0\n",
    "        \n",
    "        self.board = bonus + malus\n",
    "        self.board[self.x,self.y] = 0\n",
    "\n",
    "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
    "        self.position[0:2,:]= -1\n",
    "        self.position[:,0:2] = -1\n",
    "        self.position[-2:, :] = -1\n",
    "        #self.position[-2:, :] = -1\n",
    "        self.position[:, -2:] = -1\n",
    "        self.t = 0\n",
    "        \n",
    "        self.malus_position = np.zeros((self.grid_size, self.grid_size))\n",
    "        \n",
    "        # 3 \"feature\" states instead of 2\n",
    "        state = np.concatenate((self.malus_position.reshape(self.grid_size, self.grid_size,1),\n",
    "                                        self.board.reshape(self.grid_size, self.grid_size,1),\n",
    "                                self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
    "        \n",
    "        state = state[self.x - 2:self.x + 3, self.y - 2:self.y + 3, :]\n",
    "        return state\n",
    "    \n",
    "## use those samples of code:\n",
    "#In train explore:\n",
    "# state, reward, game_over = env.act(action, train=True)\n",
    "\n",
    "## In Environment exploring:\n",
    "# You will have to change n_state to 3 because you will use one more layer!\n",
    "#         reward = 0\n",
    "#         if train:\n",
    "#             reward = -self.malus_position[self.x, self.y]\n",
    "#         self.malus_position[self.x, self.y] = 0.1\n",
    "\n",
    "# reward = reward + self.board[self.x, self.y]\n",
    "# # 3 \"feature\" states instead of 2\n",
    "# state = np.concatenate((self.malus_position.reshape(self.grid_size, self.grid_size,1),\n",
    "#                                 self.board.reshape(self.grid_size, self.grid_size,1),\n",
    "#                         self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000/021 | Loss 0.0069 | Win/lose count 4.5/9.0 (-4.5)\n",
      "Epoch 001/021 | Loss 0.0066 | Win/lose count 5.0/9.0 (-4.0)\n",
      "Epoch 002/021 | Loss 0.0051 | Win/lose count 9.5/6.0 (3.5)\n",
      "Epoch 003/021 | Loss 0.0088 | Win/lose count 13.5/4.0 (9.5)\n",
      "Epoch 004/021 | Loss 0.0044 | Win/lose count 8.0/0 (8.0)\n",
      "Epoch 005/021 | Loss 0.0072 | Win/lose count 9.5/2.0 (7.5)\n",
      "Epoch 006/021 | Loss 0.0054 | Win/lose count 9.0/4.0 (5.0)\n",
      "Epoch 007/021 | Loss 0.0094 | Win/lose count 12.5/6.0 (6.5)\n",
      "Epoch 008/021 | Loss 0.0129 | Win/lose count 14.5/5.0 (9.5)\n",
      "Epoch 009/021 | Loss 0.0122 | Win/lose count 10.0/5.0 (5.0)\n",
      "Epoch 010/021 | Loss 0.0053 | Win/lose count 15.0/5.0 (10.0)\n",
      "Epoch 011/021 | Loss 0.0058 | Win/lose count 15.0/4.0 (11.0)\n",
      "Epoch 012/021 | Loss 0.0527 | Win/lose count 22.5/3.0 (19.5)\n",
      "Epoch 013/021 | Loss 0.0429 | Win/lose count 22.5/2.0 (20.5)\n",
      "Epoch 014/021 | Loss 0.0037 | Win/lose count 10.5/1.0 (9.5)\n",
      "Epoch 015/021 | Loss 0.0035 | Win/lose count 16.0/4.0 (12.0)\n",
      "Epoch 016/021 | Loss 0.0053 | Win/lose count 22.5/5.0 (17.5)\n",
      "Epoch 017/021 | Loss 0.0077 | Win/lose count 4.5/2.0 (2.5)\n",
      "Epoch 018/021 | Loss 0.0058 | Win/lose count 14.0/1.0 (13.0)\n",
      "Epoch 019/021 | Loss 0.0092 | Win/lose count 19.5/6.0 (13.5)\n",
      "Epoch 020/021 | Loss 0.0055 | Win/lose count 16.0/1.0 (15.0)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" controls>\n",
       "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training\n",
    "cnn_epochs_train_explore = 21\n",
    "\n",
    "env = EnvironmentExploring(grid_size=size, max_time=T, temperature=0.3)\n",
    "agent = DQN_CNN(size, lr=0.01, momentum=0.9, epsilon = 0.1, memory_size=2000, batch_size = 32,n_state=3)\n",
    "results = train_explore(agent, env, cnn_epochs_train_explore, prefix='cnn_train_explore')\n",
    "\n",
    "HTML(display_videos('cnn_train_explore20.mp4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" controls>\n",
       "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(display_videos('cnn_train_explore20.mp4'))\n",
    "\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# plt.subplot(221)\n",
    "# plt.plot(results['loss'])\n",
    "# plt.ylabel('loss')\n",
    "# plt.subplot(222)\n",
    "# plt.plot(results['score'])\n",
    "# plt.ylabel('score')\n",
    "# plt.subplot(223)\n",
    "# plt.plot(results['win'])\n",
    "# plt.ylabel('win')\n",
    "# plt.subplot(224)\n",
    "# plt.plot(results['lose'])\n",
    "# plt.ylabel('lose')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Win/lose count 9.0/1.0. Average score (8.0)\n",
      "Win/lose count 17.5/0. Average score (12.75)\n",
      "Win/lose count 19.5/3.0. Average score (14.0)\n",
      "Win/lose count 19.5/2.0. Average score (14.875)\n",
      "Win/lose count 13.5/8.0. Average score (13.0)\n",
      "Win/lose count 21.0/3.0. Average score (13.833333333333334)\n",
      "Win/lose count 22.0/1.0. Average score (14.857142857142858)\n",
      "Win/lose count 21.5/7.0. Average score (14.8125)\n",
      "Win/lose count 15.0/3.0. Average score (14.5)\n",
      "Win/lose count 18.5/5.0. Average score (14.4)\n",
      "Win/lose count 22.0/3.0. Average score (14.818181818181818)\n",
      "Win/lose count 24.5/5.0. Average score (15.208333333333334)\n",
      "Win/lose count 12.5/2.0. Average score (14.846153846153847)\n",
      "Win/lose count 23.5/3.0. Average score (15.25)\n",
      "Win/lose count 15.5/0. Average score (15.266666666666667)\n",
      "Win/lose count 14.5/2.0. Average score (15.09375)\n",
      "Win/lose count 19.0/5.0. Average score (15.029411764705882)\n",
      "Win/lose count 11.0/6.0. Average score (14.472222222222221)\n",
      "Win/lose count 18.5/2.0. Average score (14.578947368421053)\n",
      "Win/lose count 19.0/5.0. Average score (14.55)\n",
      "Win/lose count 16.5/5.0. Average score (14.404761904761905)\n",
      "Final score: 14.404761904761905\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" controls>\n",
       "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluation\n",
    "epochs_test_explore = 21\n",
    "test(agent,env,epochs_test_explore,prefix='cnn_test_explore')\n",
    "HTML(display_videos('cnn_test_explore20.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "__BONUS question__ Use the expert DQN from the previous question to generate some winning games. Train a model that mimicks its behavior. Compare the performances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
